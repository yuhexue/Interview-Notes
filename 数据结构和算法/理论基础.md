### Array&List的区别 


内存是否连续，关系到随机读取效率。

查找数据，插入数据和删除数据。

数组需要预留空间，不利于扩展。

### 树

#### 树分类

- 满二叉树：每层都满

- 完全二叉树：只能最后一层不满，且靠左

- 二叉查找树（二叉排序树）：所有左 < 根 < 所有右（没有键值相等的点）

- 平衡二叉树：高度平衡的二叉树，具体包括如AVL树，红黑树，这两种都是常用的平衡二叉搜索树。

  严格意义上的高度平衡是差值<=1，如AVL，但是红黑树是大致高度平衡，而不严格意义限制。

- B树及其变种

- 字典树（Trie树）

#### 二叉查找树

n个节点的插入和查找、删除的平均时间复杂度均为O(logn)，最坏的情况下O(n)。

二叉查找树的高度决定了二叉查找树的查找效率。

#### 平衡二叉树之AVL树

将二叉树上结点的左子树深度减去右子树深度的值称为平衡因子BF，那么平衡二叉树上的所有结点的平衡因子只可能是-1、0 和1。AVL树是严格意义上的平衡二叉树。

n个节点的插入和查找、删除的平均时间复杂度和最差情况均为O(logn)。

增加和删除可能需要一次或多次树旋转来重新平衡这个树。频繁旋转会使插入和删除牺牲掉O(logN)左右的时间。

#### 平衡二叉树之红黑树

##### 概念：

红黑树是一种二叉查找树，但在每个节点增加一个存储位表示节点的颜色，可以是红或黑（非红即黑）。通过对任何一条从根到叶子的路径上各个节点着色的方式的限制，红黑树确保没有一条路径会比其它路径长出两倍，因此，红黑树是一种弱平衡二叉树，相对于要求严格的AVL 树来说，它的旋转次数少，所以对于搜索，插入，删除操作较多的情况下，通常使用红黑树。

##### 红黑树的特征：

1. 节点是红色或黑色。
2. 根是黑色。
3. 所有叶子都是黑色（叶子是 NIL 节点）。
4. 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。）（新增节点的父节点必须相同）
5. 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。（新增节点必须为红）

##### 调整

1. 变色
2. 左旋
3. 右旋

##### 应用

- 关联数组：如 STL 中的 map、set

##### 对比：

AVL 树是高度平衡的，频繁的插入和删除，会引起频繁的rebalance，导致效率下降；红黑树不是高度平衡的，算是一种折中，插入最多两次旋转，删除最多三次旋转。
所以红黑树在查找，插入删除的性能都是O(logn)，且性能稳定，所以STL 里面很多结构包括map 底层实现都是使用的红黑树。

相比于最简单的BST，BST最差情况下查找的时间复杂度会上升至O(n)，而红黑树最坏情况下查找效率依旧是O(logn)。所以说红黑树之所以能够在STL及Linux内核中被广泛应用就是因为其折中了两种方案，既减少了树高，又减少了建树时旋转的次数。
从红黑树的定义来看，红黑树从根到NULL的每条路径拥有相同的黑节点数（假设为n），所以最短的路径长度为n（全为黑节点情况）。因为红节点不能连续出现，所以路径最长的情况就是插入最多的红色节点，在黑节点数一致的情况下，最可观的情况就是黑红黑红排列......最长路径不会大于2n，这里路径长就是树高。

#### B 树及其变种

B树是一种多路搜索树，一般用于数据库系统和文件系统。B+树是B树的变种，B*树是B+树的变种。

##### 特点

- 一般化的二叉查找树（binary search tree）
- “矮胖”，内部（非叶子）节点可以拥有可变数量的子节点（数量范围预先定义好）

##### 应用

- 大部分文件系统、数据库系统都采用B树、B+树作为索引结构

##### 区别

- B+树中只有叶子节点会带有指向记录的指针（ROWID），而B树则所有节点都带有，在内部节点出现的索引项不会再出现在叶子节点中。
- B+树中所有叶子节点都是通过指针连接在一起，而B树不会。

##### B树的优点

对于在内部节点的数据，可直接得到，不必根据叶子节点来定位。

##### B+树的优点

- 非叶子节点不会带上 ROWID，这样，一个块中可以容纳更多的索引项，一是可以降低树的高度。二是一个内部节点可以定位更多的叶子节点。
- 叶子节点之间通过指针来连接，范围扫描将十分简单，而对于B树来说，则需要在叶子节点和内部节点不停的往返移动。

> B 树、B+ 树区别来自：[differences-between-b-trees-and-b-trees](https://stackoverflow.com/questions/870218/differences-between-b-trees-and-b-trees)、[B树和B+树的区别]

##### 红黑树、B 树、B+ 树的区别？

- 红黑树的深度比较大，而 B 树和 B+ 树的深度则相对要小一些
- B+ 树则将数据都保存在叶子节点，同时通过链表的形式将他们连接在一起。

[数据结构中的各种树](https://www.cnblogs.com/maybe2030/p/4732377.html)

### map底层为何用红黑树

红黑树是一种二叉查找树，但在每个节点增加一个存储位表示节点的颜色，可以是红或黑（非红即黑）。通过对任何一条从根到叶子的路径上各个节点着色的方式的限制，红黑树确保没有一条路径会比其它路径长出两倍，因此，红黑树是一种弱平衡二叉树，相对于要求严格的AVL 树来说，它的旋转次数少，所以对于搜索，插入，删除操作较多的情况下，通常使用红黑树。

### map和u**nordered_map**的底层实现

map 底层是基于红黑树实现的，因此map 内部元素排列是有序的。
而unordered_map 底层则是基于哈希表实现的，因此其元素的排列顺序是杂乱无序的。

对于map，其底层是基于红黑树实现的，优点如下：
1)有序性，这是map 结构最大的优点，其元素的有序性在很多应用中都会简化很多的操作
2)map 的查找、删除、增加等一系列操作时间复杂度稳定，都为logn
缺点如下：
1）查找、删除、增加等操作平均时间复杂度较慢，为logn

对于unordered_map 来说，其底层是一个哈希表，优点如下：
查找、删除、添加的速度快，时间复杂度为常数级O(c)
缺点如下：
因为unordered_map 内部基于哈希表，以（key,value）对的形式存储，因此空间占用率高
unordered_map 的查找、删除、添加的复杂度不稳定，平均为O(c)，取决于哈希函数。极端情况下可能为O(n)。

### 哈希

hash就是找到一种数据内容和数据存放地址之间的映射关系。数组的特点是：寻址容易，插入和删除困难；而链表的特点是：寻址困难，插入和删除容易。那么我们需要综合两者的特性，做出一种寻址容易，插入删除也容易的数据结构。也就是哈希表，哈希表有多种不同的实现方法

### [HashTable.cpp](DataStructure/HashTable.cpp)

#### 构造方法

- 直接定址法
- 除留余数法
- 数字分析法
- 折叠法
- 平方取中法

#### 冲突处理方法

- 链地址法：key 相同的用单链表链接

- 开放定址法

  - 线性探测法：key 相同 -> 放到 key 的下一个位置，`Hi = (H(key) + i) % m`

  - 二次探测法：key 相同 -> 放到 `Di = 1^2, -1^2, ..., ±（k)^2,(k<=m/2）`

  - 随机探测法：`H = (H(key) + 伪随机数) % m`

    线性探测的哈希表数据结构和图片：

  ```c
  typedef char KeyType;
  
  typedef struct {
  	KeyType key;
  }RcdType;
  
  typedef struct {
  	RcdType *rcd;
  	int size;
  	int count;
  	bool *tag;
  }HashTable;
  ```

### hash表的实现

hash 表的实现主要包括构造哈希和处理哈希冲突两个方面：
对于构造哈希来说，主要包括直接地址法、平方取中法、除留余数法等。
对于处理哈希冲突来说，最常用的处理冲突的方法有开放定址法、再哈希法、链地址法、建立公共溢出区等方法。

### **hash表如何rehash，**如何处理其中保存的资源 

C++的hash 表中有一个负载因子loadFactor，当loadFactor<=1 时，hash 表查找的期望复杂度为O(1). 因此，每次往hash 表中添加元素时，我们必须保证是在loadFactor <1 的情况下，才能够添加。
因此，当Hash 表中loadFactor==1 时，Hash 就需要进行rehash。rehash 过程中，会模仿C++的vector 扩容方式，Hash 表中每次发现loadFactor ==1 时，就开辟一个原来桶数组的两倍空间，称为新桶数组，然后把原来的桶数组中元素全部重新哈希到新的桶数组中。

### 解决h**ash**冲突的方法 （整理题5）

当哈希表关键字集合很大时，关键字值不同的元素可能会映象到哈希表的同一地址上，这样的现象称为哈希冲突。目前常用的解决哈希冲突的方法如下：
开放定址法: 当发生地址冲突时，按照某种方法继续探测哈希表中的其他存储单元，直到找到空位置为止。
再哈希法：当发生哈希冲突时使用另一个哈希函数计算地址值，直到冲突不再发生。这种方法不易产生聚集，但是增加计算时间，同时需要准备许多哈希函数。
链地址法：将所有哈希值相同的Key 通过链表存储。key 按顺序插入到链表中建立公共溢出区：采用一个溢出表存储产生冲突的关键字。如果公共溢出区还产生冲突，再采用处理冲突方法处理。

https://blog.csdn.net/yangquanhui1991/article/details/52172768

### epoll实现的 

Linux epoll 机制是通过红黑树和双向链表实现的。首先通过epoll_create()系统调用在内核中创建一个eventpoll 类型的句柄，其中包括红黑树根节点和双向链表头节点。然后通过epoll_ctl()系统调用，向epoll 对象的红黑树结构中添加、删除、修改感兴趣的事件，返回0标识成功，返回-1 表示失败。最后通过epoll_wait()系统调用判断双向链表是否为空，如果为空则阻塞。当文件描述符状态改变，fd 上的回调函数被调用，该函数将fd 加入到双向链表中，此时epoll_wait 函数被唤醒，返回就绪好的事件。

### 排序查找

| 排序算法                              | 平均时间复杂度 | 最差时间复杂度 | 空间复杂度 | 数据对象稳定性       |
| ------------------------------------- | -------------- | -------------- | ---------- | -------------------- |
| [冒泡排序](Algorithm/BubbleSort.h)    | O(n2)          | O(n2)          | O(1)       | 稳定                 |
| [选择排序](Algorithm/SelectionSort.h) | O(n2)          | O(n2)          | O(1)       | 数组不稳定、链表稳定 |
| [插入排序](Algorithm/InsertSort.h)    | O(n2)          | O(n2)          | O(1)       | 稳定                 |
| [快速排序](Algorithm/QuickSort.h)     | O(n*log2n)     | O(n2)          | O(log2n)   | 不稳定               |
| [堆排序](Algorithm/HeapSort.cpp)      | O(n*log2n)     | O(n*log2n)     | O(1)       | 不稳定               |
| [归并排序](Algorithm/MergeSort.h)     | O(n*log2n)     | O(n*log2n)     | O(n)       | 稳定                 |
| [希尔排序](Algorithm/ShellSort.h)     | O(n*log2n)     | O(n2)          | O(1)       | 不稳定               |
| [计数排序](Algorithm/CountSort.cpp)   | O(n+m)         | O(n+m)         | O(n+m)     | 稳定                 |
| [桶排序](Algorithm/BucketSort.cpp)    | O(n)           | O(n)           | O(m)       | 稳定                 |
| [基数排序](Algorithm/RadixSort.h)     | O(k*n)         | O(n2)          |            | 稳定                 |

| 查找算法                                              | 平均时间复杂度   | 空间复杂度 | 查找条件   |
| ----------------------------------------------------- | ---------------- | ---------- | ---------- |
| [顺序查找](Algorithm/SequentialSearch.h)              | O(n)             | O(1)       | 无序或有序 |
| [二分查找（折半查找）](Algorithm/BinarySearch.h)      | O(log2n)         | O(1)       | 有序       |
| [插值查找](Algorithm/InsertionSearch.h)               | O(log2(log2n))   | O(1)       | 有序       |
| [斐波那契查找](Algorithm/FibonacciSearch.cpp)         | O(log2n)         | O(1)       | 有序       |
| [哈希查找](DataStructure/HashTable.cpp)               | O(1)             | O(n)       | 无序或有序 |
| [二叉查找树（二叉搜索树查找）](Algorithm/BSTSearch.h) | O(log2n)         |            |            |
| [红黑树](DataStructure/RedBlackTree.cpp)              | O(log2n)         |            |            |
| 2-3树                                                 | O(log2n - log3n) |            |            |
| B树/B+树                                              | O(log2n)         |            |            |

| 图搜索算法                                                   | 数据结构          | 遍历时间复杂度           | 空间复杂度               |
| ------------------------------------------------------------ | ----------------- | ------------------------ | ------------------------ |
| [BFS广度优先搜索](https://zh.wikipedia.org/wiki/广度优先搜索) | 邻接矩阵 邻接链表 | O(\|v\|2) O(\|v\|+\|E\|) | O(\|v\|2) O(\|v\|+\|E\|) |
| [DFS深度优先搜索](https://zh.wikipedia.org/wiki/深度优先搜索) | 邻接矩阵 邻接链表 | O(\|v\|2) O(\|v\|+\|E\|) | O(\|v\|2) O(\|v\|+\|E\|) |

### 排序的对比

1.普遍认为：
当N很小时，快速排序慢，归并排序快 
当N很大时，并且有序程度高时，快速排序最快 
当N很大时，并且有序程序低时，堆排序最快

快排是目前基于比较的内部排序中被认为最好的，当待排序的关键字是随机分布时，快排的平均时间最短；
堆排序所需的辅助空间少于快速排序，并且不会出现快速排序可能出现的最坏情况。这两种排序都是不稳定的。
若要求排序稳定，则可选用归并排序。先利用直接插入排序求得较长的有序子文件，然后再两两归并之。因为直接插入排序是稳定的，所以改进后的归并排序仍是稳定的。

但是：由于快速排序不稳定，因此数据量极大时不如选用堆排序。

堆排序占花费是时间主要是在建堆的时候。
所以在数据量方面来说，如果数据量越大，堆排序的优势就越明显。
大多数商用软件都采用快排，因为它在一般情况下是排序最快的算法。
然而，快排绝不能用于需要特定响应时间的系统，除非这个系统能承受O(n^2)的时间复杂度。
如果你预先估计可能会碰到这种最坏情况，那么
如果n比较小，改用插入排序——由于代码简单，它的时间复杂度的常数项比较少
如果n比较大，改用堆排序——你应该用堆排序，因为它能保证O(nlogn)的时间复杂度.



快排最差情况推倒：
在快速排序的早期版本中呢，最左面或者是最右面的那个元素被选为枢轴，那最坏的情况就在如下情况：
1）数组已经是正序排过序的。（每次最右边的那个元素被选为枢轴）
2）数组已经是倒序排过序的。（每次最左边的那个元素被选为枢轴）
3）所有的元素都相同（1、2 的特殊情况）
因为这些案例在用例中十分常见，所以这个问题可以通过要么选择一个随机的枢轴，或者选择一个分区中间的下标作为枢轴，或者（特别是对于相比更长的分区）选择分区的第一个、中间、最后一个元素的中值作为枢轴。有了这些修改，那快排的最差的情况就不那么容易出现了，但是如果输入的数组最大（或者最小元素）被选为枢轴，那最坏的情况就又来了。快速排序，在最坏情况退化为冒泡排序，需要比较O(n2)次（n(n - 1)/2 次）。

稳定排序有：

基数排序、冒泡排序、直接插入排序、折半插入排序、归并排序

### 哈夫曼编码

哈夫曼编码是哈夫曼树的一种应用，广泛用于数据文件压缩。哈夫曼编码算法用字符在文件中出现的频率来建立使用0，1 表示个字符的最优表示方式，其具体算法如下：
(1)哈夫曼算法以自底向上的方式构造表示最优前缀码的二叉树T。
(2)算法以|C|个叶结点开始，执行|C|－1 次的“合并”运算后产生最终所要求的树T。
(3)假设编码字符集中每一字符c 的频率是f(c)。以f 为键值的优先队列Q 用在贪心选择时有效地确定算法当前要合并的2 棵具有最小频率的树。一旦2 棵具有最小频率的树合并后，产生一棵新的树，其频率为合并的2 棵树的频率之和，并将新树插入优先队列Q。经过n－1 次的合并后，优先队列中只剩下一棵树，即所要求的树T。

### 加密方法都有哪些 

1、单向加密
单向加密又称为不可逆加密算法，其密钥是由加密散列函数生成的。单向散列函数一般用于产生消息摘要，密钥加密等，常见的有：
MD5（Message Digest Algorithm 5）：是RSA 数据安全公司开发的一种单向散列算法，非可逆，相同的明文产生相同的密文；
SHA（Secure Hash Algorithm）：可以对任意长度的数据运算生成一个160 位的数值。其变种由SHA192，SHA256，SHA384 等；
CRC-32，主要用于提供校验功能；
算法特征：
输入一样，输出必然相同；
雪崩效应，输入的微小改变，将会引起结果的巨大变化；

定长输出，无论原始数据多大，结果大小都是相同的；
不可逆，无法根据特征码还原原来的数据；
2、对称加密
采用单钥密码系统的加密方法，同一个密钥可以同时用作信息的加密和解密，这种加密方法称为对称加密，也称为单密钥加密。
特点：
1、加密方和解密方使用同一个密钥；
2、加密解密的速度比较快，适合数据比较长时的使用；
3、密钥传输的过程不安全，且容易被破解，密钥管理也比较麻烦；
优点：对称加密算法的优点是算法公开、计算量小、加密速度快、加密效率高。
缺点：对称加密算法的缺点是在数据传送前，发送方和接收方必须商定好秘钥，然后使双方都能保存好秘钥。其次如果一方的秘钥被泄露，那么加密信息也就不安全了。另外，每对用户每次使用对称加密算法时，都需要使用其他人不知道的唯一秘钥，这会使得收、发双方所拥有的钥匙数量巨大，密钥管理成为双方的负担。

3、非对称加密
非对称密钥加密也称为公钥加密，由一对公钥和私钥组成。公钥是从私钥提取出来的。可以用公钥加密，再用私钥解密，这种情形一般用于公钥加密，当然也可以用私钥加密，用公钥解密。常用于数字签名，因此非对称加密的主要功能就是加密和数字签名。
特征：
1）秘钥对，公钥(public key)和私钥(secret key)
2）主要功能：加密和签名
发送方用对方的公钥加密，可以保证数据的机密性（公钥加密）。
发送方用自己的私钥加密，可以实现身份验证（数字签名）。
3）公钥加密算法很少用来加密数据，速度太慢，通常用来实现身份验证。
常用的非对称加密算法
RSA：由RSA 公司发明，是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的；既可以实现加密，又可以实现签名。
DSA（Digital Signature Algorithm）：数字签名算法，是一种标准的DSS（数字签名标准）。
ECC（Elliptic Curves Cryptography）：椭圆曲线密码编码。

### 什么是LRU缓存 

 LRU(最近最少使用)算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高
实现：使用一个链表保存缓存数据，将新数据插入到头部，每当缓存命中时，则将命中的数据移动到链表头部，当链表满的时候，将链表尾部的数据丢弃。






