### TCP怎么保证可靠性，**并且**简述**一下**TCP建立连接和断开连接的过程 ，如何使UDP可靠

TCP 保证可靠性：
（1）序列号、确认应答、超时重传
数据到达接收方，接收方需要发出一个确认应答，表示已经收到该数据段，并且确认序号会
说明了它下一次需要接收的数据序列号。如果发送发迟迟未收到确认应答，那么可能是发送的数
据丢失，也可能是确认应答丢失，这时发送方在等待一定时间后会进行重传。这个时间一般是
2*RTT(报文段往返时间）+一个偏差值。
（2）窗口控制与高速重发控制/快速重传（重复确认应答）
TCP 会利用窗口控制来提高传输速度，意思是在一个窗口大小内，不用一定要等到应答才能
发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控
制，每一个没收到确认应答的数据都要重发。
使用窗口控制，如果数据段1001-2000 丢失，后面数据每次传输，确认应答都会不停地发送
序号为1001 的应答，表示我要接收1001 开始的数据，发送端如果收到3 次相同应答，就会立刻
进行重发；但还有种情况有可能是数据都收到了，但是有的应答丢失了，这种情况不会进行重发，
因为发送端知道，如果是数据段丢失，接收端不会放过它的，会疯狂向它提醒......
（3）拥塞控制

如果把窗口定的很大，发送端连续发送大量的数据，可能会造成网络的拥堵（大家都在用网，
你在这狂发，吞吐量就那么大，当然会堵），甚至造成网络的瘫痪。所以TCP 在为了防止这种情
况而进行了拥塞控制。
慢启动：定义拥塞窗口，一开始将该窗口大小设为1，之后每次收到确认应答（经过一个rtt），
将拥塞窗口大小*2。
拥塞避免：设置慢启动阈值，一般开始都设为65536。拥塞避免是指当拥塞窗口大小达到这
个阈值，拥塞窗口的值不再指数上升，而是加法增加（每次确认应答/每个rtt，拥塞窗口大小
+1），以此来避免拥塞。
将报文段的超时重传看做拥塞，则一旦发生超时重传，我们需要先将阈值设为当前窗口大小
的一半，并且将窗口大小设为初值1，然后重新进入慢启动过程。
快速重传：在遇到3 次重复确认应答（高速重发控制）时，代表收到了3 个报文段，但是这
之前的1 个段丢失了，便对它进行立即重传。
然后，先将阈值设为当前窗口大小的一半，然后将拥塞窗口大小设为慢启动阈值+3 的大小。
这样可以达到：在TCP 通信时，网络吞吐量呈现逐渐的上升，并且随着拥堵来降低吞吐量，
再进入慢慢上升的过程，网络不会轻易的发生瘫痪。



TCP 建立连接和断开连接的过程：

![8](C:\Users\yuhexue\Desktop\8.png)

三次握手：
1. Client 将标志位SYN 置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client
    进入SYN_SENT 状态，等待Server 确认。

2. Server 收到数据包后由标志位SYN=1 知道Client 请求建立连接，Server 将标志位SYN
    和ACK 都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client 以确认连接请
    求，Server 进入SYN_RCVD 状态。

3. Client 收到确认后，检查ack 是否为J+1，ACK 是否为1，如果正确则将标志位ACK 置为
    1，ack=K+1，并将该数据包发送给Server，Server 检查ack 是否为K+1，ACK 是否为1，如果正
    确则连接建立成功，Client 和Server 进入ESTABLISHED 状态，完成三次握手，随后Client 与
    Server 之间可以开始传输数据了。

  

  四次挥手：
  由于TCP 连接时全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成
  数据发送任务后，发送一个FIN 来终止这一方向的连接，收到一个FIN 只是意味着这一方向上没
  有数据流动了，即不会再收到数据了，但是在这个TCP 连接上仍然能够发送数据，直到这一方向
  也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。

  1.数据传输结束后，客户端的应用进程发出连接释放报文段，并停止发送数据，客户端进入
  FIN_WAIT_1 状态，此时客户端依然可以接收服务器发送来的数据。
  2.服务器接收到FIN 后，发送一个ACK 给客户端，确认序号为收到的序号+1，服务器进入
  CLOSE_WAIT 状态。客户端收到后进入FIN_WAIT_2 状态。
  3.当服务器没有数据要发送时，服务器发送一个FIN 报文，此时服务器进入LAST_ACK 状态，
  等待客户端的确认
  4.客户端收到服务器的FIN 报文后，给服务器发送一个ACK 报文，确认序列号为收到的序号
  +1。此时客户端进入TIME_WAIT 状态，等待2MSL（MSL：报文段最大生存时间），然后关闭连接。



三次握手四次挥手的原因

三次握手的原因：三次握手可以防止已经失效的连接请求报文突然又传输到服务器端导致的
服务器资源浪费。例如，客户端先发送了一个SYN，但是由于网络阻塞，该SYN 数据包在某个节
点长期滞留。然后客户端又重传SYN 数据包并正确建立TCP 连接，然后传输完数据后关闭该连接。
该连接释放后失效的SYN 数据包才到达服务器端。在二次握手的前提下，服务器端会认为这是客
户端发起的又一次请求，然后发送SYN ，并且在服务器端创建socket 套接字，一直等待客户端
发送数据。但是由于客户端并没有发起新的请求，所以会丢弃服务端的SYN 。此时服务器会一
直等待客户端发送数据从而造成资源浪费。



四次挥手的原因：由于连接的关闭控制权在应用层，所以被动关闭的一方在接收到FIN 包时，
TCP 协议栈会直接发送一个ACK 确认包，优先关闭一端的通信。然后通知应用层，由应用层决定
什么时候发送FIN 包。应用层可以使用系统调用函数read==0 来判断对端是否关闭连接。





### 请问tcp握手为什么两次不可以？为什么不用四次？

两次不可以：tcp 是全双工通信，两次握手只能确定单向数据链路是可以通信的，并不能保
证反向的通信正常
不用四次：
本来握手应该和挥手一样都是需要确认两个方向都能联通的，本来模型应该是：
1.客户端发送syn0 给服务器
2.服务器收到syn0，回复ack(syn0+1)
3.服务器发送syn1
4.客户端收到syn1，回复ack(syn1+1)
因为tcp 是全双工的，上边的四部确认了数据在两个方向上都是可以正确到达的，但是2，3 步
没有没有上下的联系，可以将其合并，加快握手效率，所有就变成了3 步握手。



再看下21题



### 四层TCP的模型，状态转移 

四层TCP/IP 模型如下：

![9](C:\Users\yuhexue\Desktop\9.png)

状态转移图：

![10](C:\Users\yuhexue\Desktop\10.png)

### **HTTP和HTTPS的区别，**以及**HTTPS有什么**缺点

1）HTTP 协议：
HTTP 协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写，是用于从万维网
（WWW:World Wide Web）服务器传输超文本到本地浏览器的传送协议。

HTTP 是一个基于TCP/IP 通信协议来传递数据（HTML 文件，图片文件，查询结果等）。
HTTP 是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒
体信息系统。它于1990 年提出，经过几年的使用与发展，得到不断地完善和扩展。目前在WWW
中使用的是HTTP/1.0 的第六版，HTTP/1.1 的规范化工作正在进行之中，而且HTTP-NG（Next
Generation of HTTP）的建议已经提出。
HTTP 协议工作于客户端-服务端架构为上。浏览器作为HTTP 客户端通过URL 向HTTP 服务端
即WEB 服务器发送所有请求。Web 服务器根据接收到的请求后，向客户端发送响应信息。
2）HTTP 协议特点
1、简单快速：
客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。
每种方法规定了客户与服务器联系的类型不同。由于HTTP 协议简单，使得HTTP 服务器的程序规
模小，因而通信速度很快。
2、灵活：
HTTP 允许传输任意类型的数据对象。正在传输的类型由Content-Type 加以标记。
3、无连接：
无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应
答后，即断开连接。采用这种方式可以节省传输时间。

4、无状态：
HTTP 协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如
果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方
面，在服务器不需要先前信息时它的应答就较快。
5、支持B/S 及C/S 模式。
6、默认端口80
7、基于TCP 协议
3）HTTP 过程概述：
HTTP 协议定义Web 客户端如何从Web 服务器请求Web 页面，以及服务器如何把Web 页面传
送给客户端。HTTP 协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包
含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的
内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。
HTTP 请求/响应的步骤如下：
1、客户端连接到Web 服务器

一个HTTP 客户端，通常是浏览器，与Web 服务器的HTTP 端口（默认为80）建立一个TCP
套接字连接。例如，http://www.baidu.com。
2、发送HTTP 请求
通过TCP 套接字，客户端向Web 服务器发送一个文本的请求报文，一个请求报文由请求行、
请求头部、空行和请求数据4 部分组成。
3、服务器接受请求并返回HTTP 响应
Web 服务器解析请求，定位请求资源。服务器将资源复本写到TCP 套接字，由客户端读取。
一个响应由状态行、响应头部、空行和响应数据4 部分组成。
4、释放连接TCP 连接
若connection 模式为close，则服务器主动关闭TCP 连接，客户端被动关闭连接，释放TCP
连接;若connection 模式为keepalive，则该连接会保持一段时间，在该时间内可以继续接收请
求;
5、客户端浏览器解析HTML 内容
客户端浏览器首先解析状态行，查看表明请求是否成功的状态代码。然后解析每一个响应头，
响应头告知以下为若干字节的HTML 文档和文档的字符集。客户端浏览器读取响应数据HTML，根
据HTML 的语法对其进行格式化，并在浏览器窗口中显示。

4、举例：
在浏览器地址栏键入URL，按下回车之后会经历以下流程：
1、浏览器向DNS 服务器请求解析该URL 中的域名所对应的IP 地址；
2、解析出IP 地址后，根据该IP 地址和默认端口80，和服务器建立TCP 连接；
3、浏览器发出读取文件（URL 中域名后面部分对应的文件）的HTTP 请求，该请求报文作为
TCP 三次握手的第三个报文的数据发送给服务器；
4、服务器对浏览器请求作出响应，并把对应的html 文本发送给浏览器；
5、释放TCP 连接；
6、浏览器将该html 文本并显示内容；



HTTP 协议和HTTPS 协议区别如下：
1）HTTP 协议是以明文的方式在网络中传输数据，而HTTPS 协议传输的数据则是经过TLS 加
密后的，HTTPS 具有更高的安全性
2）HTTPS 在TCP 三次握手阶段之后，还需要进行SSL 的handshake，协商加密使用的对称
加密密钥
3）HTTPS 协议需要服务端申请证书，浏览器端安装对应的根证书
4）HTTP 协议端口是80，HTTPS 协议端口是443
HTTPS 优点：
HTTPS 传输数据过程中使用密钥进行加密，所以安全性更高
HTTPS 协议可以认证用户和服务器，确保数据发送到正确的用户和服务器

HTTPS 缺点：
HTTPS 握手阶段延时较高：由于在进行HTTP 会话之前还需要进行SSL 握手，因此HTTPS 协
议握手阶段延时增加
HTTPS 部署成本高：一方面HTTPS 协议需要使用证书来验证自身的安全性，所以需要购买CA
证书；另一方面由于采用HTTPS 协议需要进行加解密的计算，占用CPU 资源较多，需要的服务器
配置或数目高



HTTP 协议和HTTPS 协议区别如下：
1）HTTP 协议是以明文的方式在网络中传输数据，而HTTPS 协议传输的数据则是经过TLS 加
密后的，HTTPS 具有更高的安全性
2）HTTPS 在TCP 三次握手阶段之后，还需要进行SSL 的handshake，协商加密使用的对称
加密密钥
3）HTTPS 协议需要服务端申请证书，浏览器端安装对应的根证书
4）HTTP 协议端口是80，HTTPS 协议端口是443

### HTTP**返回码** 

HTTP 协议的响应报文由状态行、响应头部和响应包体组成，其响应状态码总体描述如下：
1xx：指示信息--表示请求已接收，继续处理。
2xx：成功--表示请求已被成功接收、理解、接受。
3xx：重定向--要完成请求必须进行更进一步的操作。
4xx：客户端错误--请求有语法错误或请求无法实现。
5xx：服务器端错误--服务器未能实现合法的请求。
常见状态代码、状态描述的详细说明如下。
200 OK：客户端请求成功。

206 partial content 服务器已经正确处理部分GET 请求，实现断点续传或同时分片下载，
该请求必须包含Range 请求头来指示客户端期望得到的范围
300 multiple choices（可选重定向）:被请求的资源有一系列可供选择的反馈信息，由浏
览器/用户自行选择其中一个。
301 moved permanently（永久重定向）：该资源已被永久移动到新位置，将来任何对该
资源的访问都要使用本响应返回的若干个URI 之一。
302 move temporarily(临时重定向)：请求的资源现在临时从不同的URI 中获得，
304：not modified :如果客户端发送一个待条件的GET 请求并且该请求以经被允许，而文
档内容未被改变，则返回304,该响应不包含包体（即可直接使用缓存）。
403 Forbidden：服务器收到请求，但是拒绝提供服务。
t Found：请求资源不存在，举个例子：输入了错误的URL。

### GET和POST的区别

1、概括
对于GET 方式的请求，浏览器会把http header 和data 一并发送出去，服务器响应200（返
回数据）；
而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务
器响应200 ok（返回数据）
2、区别：
1、get 参数通过url 传递，post 放在request body 中。
2、get 请求在url 中传递的参数是有长度限制的，而post 没有。
3、get 比post 更不安全，因为参数直接暴露在url 中，所以不能用来传递敏感信息。
4、get 请求只能进行url 编码，而post 支持多种编码方式。
5、get 请求会浏览器主动cache，而post 支持多种编码方式。
6、get 请求参数会被完整保留在浏览历史记录里，而post 中的参数不会被保留。
7、GET 和POST 本质上就是TCP 链接，并无差别。但是由于HTTP 的规定和浏览器/服务器的
限制，导致他们在应用过程中体现出一些不同。
8、GET 产生一个TCP 数据包；POST 产生两个TCP 数据包。

### socket编程中C/S的主要函数流程，函数介绍

见24题

### IP**地址作用**，**以及**M**AC**地址作用 

MAC 地址是一个硬件地址，用来定义网络设备的位置，主要由数据链路层负责。而IP 地址
是IP 协议提供的一种统一的地址格式，为互联网上的每一个网络和每一台主机分配一个逻辑地
址，以此来屏蔽物理地址的差异。

### 操作系统中的中断 

中断是指CPU 对系统发生的某个事件做出的一种反应，CPU 暂停正在执行的程序，保存现场
后自动去执行相应的处理程序，处理完该事件后再返回中断处继续执行原来的程序。中断一般三
类，一种是由CPU 外部引起的，如I/O 中断、时钟中断，一种是来自CPU 内部事件或程序执行中
引起的中断，例如程序非法操作，地址越界、浮点溢出），最后一种是在程序中使用了系统调用
引起的。而中断处理一般分为中断响应和中断处理两个步骤，中断响应由硬件实施，中断处理主
要由软件实施。

**9**.**请回答**OSI**七层模型和T**CP/IP**四层模型，每层列举2个协议**

OSI 七层模型及其包含的协议如下:
物理层: 通过媒介传输比特,确定机械及电气规范,传输单位为bit，主要包括的协议为：
IEE802.3 CLOCK RJ45
数据链路层: 将比特组装成帧和点到点的传递,传输单位为帧,主要包括的协议为MAC VLAN
PPP
网络层：负责数据包从源到宿的传递和网际互连，传输单位为包,主要包括的协议为IP ARP
ICMP
传输层：提供端到端的可靠报文传递和错误恢复，传输单位为报文,主要包括的协议为TCP
UDP
会话层：建立、管理和终止会话，传输单位为SPDU，主要包括的协议为RPC NFS 

表示层: 对数据进行翻译、加密和压缩,传输单位为PPDU，主要包括的协议为JPEG ASII
应用层: 允许访问OSI 环境的手段,传输单位为APDU，主要包括的协议为FTP HTTP DNS
TCP/IP 4 层模型包括：
网络接口层：MAC VLAN
网络层:IP ARP ICMP
传输层:TCP UDP
应用层:HTTP DNS SMTP

### 搜索baidu，会用到计算机网络中的什么层？每层是干什么的 

浏览器要将URL 解析为IP 地址，解析域名就要用到DNS 协议，首先主机会查询DNS 的缓存，
如果没有就给本地DNS 发送查询请求。DNS 查询分为两种方式，一种是递归查询，一种是迭代查
询。如果是迭代查询，本地的DNS 服务器，向根域名服务器发送查询请求，根域名服务器告知该
域名的一级域名服务器，然后本地服务器给该一级域名服务器发送查询请求，然后依次类推直到
查询到该域名的IP 地址。DNS 服务器是基于UDP 的，因此会用到UDP 协议。

得到IP 地址后，浏览器就要与服务器建立一个http 连接。因此要用到http 协议，http 协
议报文格式上面已经提到。http 生成一个get 请求报文，将该报文传给TCP 层处理，所以还会
用到TCP 协议。如果采用https 还会使用https 协议先对http 数据进行加密。TCP 层如果有需
要先将HTTP 数据包分片，分片依据路径MTU 和MSS。TCP 的数据包然后会发送给IP 层，用到IP
协议。IP 层通过路由选路，一跳一跳发送到目的地址。当然在一个网段内的寻址是通过以太网
协议实现(也可以是其他物理层协议，比如PPP，SLIP)，以太网协议需要直到目的IP 地址的物
理地址，有需要ARP 协议。
其中：
1、DNS 协议，http 协议，https 协议属于应用层
应用层是体系结构中的最高层。应用层确定进程之间通信的性质以满足用户的需要。这里的
进程就是指正在运行的程序。应用层不仅要提供应用进程所需要的信息交换和远地操作，而且还
要作为互相作用的应用进程的用户代理，来完成一些为进行语义上有意义的信息交换所必须的功
能。应用层直接为用户的应用进程提供服务。
2、TCP/UDP 属于传输层
传输层的任务就是负责主机中两个进程之间的通信。因特网的传输层可使用两种不同协议：
即面向连接的传输控制协议TCP，和无连接的用户数据报协议UDP。面向连接的服务能够提供可
靠的交付，但无连接服务则不保证提供可靠的交付，它只是“尽最大努力交付”。这两种服务方
式都很有用，备有其优缺点。在分组交换网内的各个交换结点机都没有传输层。

3、IP 协议，ARP 协议属于网络层
网络层负责为分组交换网上的不同主机提供通信。在发送数据时，网络层将运输层产生的报
文段或用户数据报封装成分组或包进行传送。在TCP/IP 体系中，分组也叫作IP 数据报，或简称
为数据报。网络层的另一个任务就是要选择合适的路由，使源主机运输层所传下来的分组能够交
付到目的主机。
4、数据链路层
当发送数据时，数据链路层的任务是将在网络层交下来的IP 数据报组装成帧，在两个相邻
结点间的链路上传送以帧为单位的数据。每一帧包括数据和必要的控制信息（如同步信息、地址
信息、差错控制、以及流量控制信息等）。控制信息使接收端能够知道—个帧从哪个比特开始和
到哪个比特结束。控制信息还使接收端能够检测到所收到的帧中有无差错。
5、物理层
物理层的任务就是透明地传送比特流。在物理层上所传数据的单位是比特。传递信息所利用
的一些物理媒体，如双绞线、同轴电缆、光缆等，并不在物理层之内而是在物理层的下面。因此
也有人把物理媒体当做第0 层。

### TCP拥塞控制？**以及**达到什么情况的时候开始减慢增长的速度



发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。拥塞窗口的大小取
决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到
接受方的接收能力，发送窗口可能小于拥塞窗口。慢开始算法的思路就是，不要一开始就发送大
量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。
过程cwnd 的大小呈指数增长，直到超过慢启动门限，然后进入拥塞避免阶段，cwnd 的大小线性
增长，当出现网络拥塞(三个重复的ack 或者超时)时候，将慢启动门限设置为出现拥塞时候大小
的一半，cwnd 的大小重新从0 开始进入慢启动阶段。
快重传和快恢复：快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使
发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，
发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置
的重传计时器时间到期





拥塞控制是防止过多的数据注入网络，使得网络中的路由器或者链路过载。流量控制是点对
点的通信量控制，而拥塞控制是全局的网络流量整体性的控制。发送双方都有一个拥塞窗口——
cwnd。
1、慢开始
最开始发送方的拥塞窗口为1，由小到大逐渐增大发送窗口和拥塞窗口。每经过一个传输轮
次，拥塞窗口cwnd 加倍。当cwnd 超过慢开始门限，则使用拥塞避免算法，避免cwnd 增长过大。
2、拥塞避免
每经过一个往返时间RTT，cwnd 就增长1。
在慢开始和拥塞避免的过程中，一旦发现网络拥塞，就把慢开始门限设为当前值的一半，并
且重新设置cwnd 为1，重新慢启动。（乘法减小，加法增大）
3、快重传
接收方每次收到一个失序的报文段后就立即发出重复确认，发送方只要连续收到三个重复确
认就立即重传（尽早重传未被确认的报文段）。
4、快恢复
当发送方连续收到了三个重复确认，就乘法减半（慢开始门限减半），将当前的cwnd 设置
为慢开始门限，并且采用拥塞避免算法（连续收到了三个重复请求，说明当前网络可能没有拥塞）。
采用快恢复算法时，慢开始只在建立连接和网络超时才使用。

达到什么情况的时候开始减慢增长的速度？
采用慢开始和拥塞避免算法的时候
1. 一旦cwnd>慢开始门限，就采用拥塞避免算法，减慢增长速度
2. 一旦出现丢包的情况，就重新进行慢开始，减慢增长速度
    采用快恢复和快重传算法的时候
3. 一旦cwnd>慢开始门限，就采用拥塞避免算法，减慢增长速度
4. 一旦发送方连续收到了三个重复确认，就采用拥塞避免算法，减慢增长速度

### TCP/UDP的区别

1）TCP 和UDP 区别
1） 连接
TCP 是面向连接的传输层协议，即传输数据之前必须先建立好连接。
UDP 无连接。
2） 服务对象
TCP 是点对点的两点间服务，即一条TCP 连接只能有两个端点；
UDP 支持一对一，一对多，多对一，多对多的交互通信。
3） 可靠性
TCP 是可靠交付：无差错，不丢失，不重复，按序到达。
UDP 是尽最大努力交付，不保证可靠交付。
4）拥塞控制，流量控制
TCP 有拥塞控制和流量控制保证数据传输的安全性。
UDP 没有拥塞控制，网络拥塞不会影响源主机的发送效率。

5） 报文长度
TCP 是动态报文长度，即TCP 报文长度是根据接收方的窗口大小和当前网络拥塞情况决定的。
UDP 面向报文，不合并，不拆分，保留上面传下来报文的边界。
6) 首部开销
TCP 首部开销大，首部20 个字节。
UDP 首部开销小，8 字节。（源端口，目的端口，数据长度，校验和）

2）TCP 和UDP 适用场景
从特点上我们已经知道，TCP 是可靠的但传输速度慢，UDP 是不可靠的但传输速度快。因此
在选用具体协议通信时，应该根据通信数据的要求而决定。

若通信数据完整性需让位与通信实时性，则应该选用TCP 协议（如文件传输、重要状态的
更新等）；反之，则使用UDP 协议（如视频传输、实时通信等）。

### TCP/IP数据链路层的交互过程 

网络层等到数据链层用mac 地址作为通信目标，数据包到达网络等准备往数据链层发送的时
候，首先会去自己的arp 缓存表(存着ip-mac 对应关系)去查找改目标ip 的mac 地址，如果查到
了，就讲目标ip 的mac 地址封装到链路层数据包的包头。如果缓存中没有找到，会发起一个广
播：who is ip XXX tell ip XXX,所有收到的广播的机器看这个ip 是不是自己的，如果是自己
的，则以单拨的形式将自己的mac 地址回复给请求的机器

### 请问server端监听端口，但还没有客户端连接进来，此时进程处于什么状态？

这个需要看服务端的编程模型，如果如上一个问题的回答描述的这样，则处于阻塞状态，如
果使用了epoll,select 等这样的io 复用情况下，处于运行状态

### 同步异步，阻塞和非阻塞的区别

同步和异步：调用者必须循环自去查看事件有没有发生，这种情况是同步。调用者不用自己去查
看事件有没有发生，而是等待着注册在事件上的回调函数通知自己，这种情况是异步。

阻塞和非阻塞：调用者在事件没有发生的时候，一直在等待事件发生，不能去处理别的任务这是
阻塞。调用者在事件没有发生的时候，可以去处理别的任务这是非阻塞。









```
key:TCP是一种面向连接的、可靠的、字节流服务
 
1.面向链接：TCP面向链接，面向连接意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须通过三次握手先建立一个TCP连接。在一个TCP中仅有两方彼此通信，多播和广播不能用于TCP。UDP是不可靠的传输，传输前不需要建立链接，可以应用多播和广播实现一对多的通信。 
 
2.可靠性：TCP提供端到端的流量控制，对收到的数据进行确认，采用超时重发，对失序的数据进行重新排序等机制保证数据通信的可靠性。而UDP是一种不可靠的服务，接收方可能不能收到发送方的数据报。
 
3.TCP是一种流模式的协议，UDP是一种数据报模式的协议。进程的每个输出操作都正好产生一个UDP数据报，并组装成一份待发送的IP数据报。TCP应用程序产生的全体数据与真正发送的单个IP数据报可能没有什么联系。TCP会有粘包和半包的现象。
  
4.效率上：速度上，一般TCP速度慢，传输过程中需要对数据进行确认，超时重发，还要对数据进行排序。UDP没有这些机制所以速度快。数据比例，TCP头至少20个字节，UDP头8个字节，相对效率高。组装效率上：TCP头至少20个字节，UDP头8个字节，系统组装上TCP相对慢。
 
5.用途上：用于TCP可靠性，http，ftp使用。而由于UDP速度快，视频，在线游戏多用UDP，保证实时性
 
 
对于第三点的理解。TCP可能发送100个“包”，而接收到50个“包”，不是丢“包”了，而是每次接受的“包”都比发送的多，其实TCP并没有包的概念。例如，每次发10个字节，可能读得时候一次读了20个字节。TCP是一种流模式的协议，在接收到的缓存中按照发送的包得顺序自动按照顺序拼接好，因为数据基本来自同一个主机，而且是按照顺序发送过来的，TCP的缓存中存放的就是，连续的数据。感觉好像是多封装了一步比UDP。而UDP因为可能两个不同的主机，给同一个主机发送，（一个端口可能收到多个应用程序的数据），或者按照TCP那样合并数据，必然会造成数据错误。我觉得关键的原因还是，TCP是面向连接，而UDP是无连接的，这就导致，TCP接收的数据为一个主机发来且有序无误的，而UDP可能是多个主机发来的无序，可能错误的。
```

TCP和UDP头部字节定义，

TCP和UDP三次握手和四次挥手状态及消息类型,

time_wait，close_wait状态产生原因，keepalive，

```
TIME_WAIT：表示收到了对方的FIN报文，并发送出了ACK报文。 TIME_WAIT状态下的TCP连接会等待2*MSL（Max Segment Lifetime，最大分段生存期，指一个TCP报文在Internet上的最长生存时间。每个具体的TCP协议实现都必须选择一个确定的MSL值，RFC 1122建议是2分钟，但BSD传统实现采用了30秒，Linux可以cat /proc/sys/net/ipv4/tcp_fin_timeout看到本机的这个值），然后即可回到CLOSED 可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。
 
如果使用了nginx代理，那么系统TIME_WAIT的数量会变得比较多，这是由于nginx代理使用了短链接的方式和后端交互的原因，使得nginx和后端的ESTABLISHED变得很少而TIME_WAIT很多。这不但发生在安装nginx的代理服务器上，而且也会使后端的app服务器上有大量的TIME_WAIT。查阅TIME_WAIT资料，发现这个状态很多也没什么大问题，但可能因为它占用了系统过多的端口，导致后续的请求无法获取端口而造成障碍。
 
虽然TIME_WAIT会造成一些问题，但是要完全枪毙掉它也是不正当的，虽然看起来这么做没什么错。具体可看这篇文档：
 
http://hi.baidu.com/tim_bi/blog/item/35b005d784ca91d5a044df1d.html
 
所以目前看来最好的办法是让每个TIME_WAIT早点过期。
 
在linux上可以这么配置：
 
#让TIME_WAIT状态可以重用，这样即使TIME_WAIT占满了所有端口，也不会拒绝新的请求造成障碍
echo "1" > /proc/sys/net/ipv4/tcp_tw_reuse
#让TIME_WAIT尽快回收，我也不知是多久，观察大概是一秒钟
echo "1" > /proc/sys/net/ipv4/tcp_tw_recycle
 
很多文档都会建议两个参数都配置上，但是我发现只用修改tcp_tw_recycle就可以解决问题的了，TIME_WAIT重用TCP协议本身就是不建议打开的。
 
不能重用端口可能会造成系统的某些服务无法启动，比如要重启一个系统监控的软件，它用了40000端口，而这个端口在软件重启过程中刚好被使用了，就可能会重启失败的。linux默认考虑到了这个问题，有这么个设定：
 
#查看系统本地可用端口极限值
cat /proc/sys/net/ipv4/ip_local_port_range
 
用这条命令会返回两个数字，默认是：32768 61000，说明这台机器本地能向外连接61000-32768=28232个连接，注意是本地向外连接，不是这台机器的所有连接，不会影响这台机器的80端口的对外连接数。但这个数字会影响到代理服务器（nginx）对app服务器的最大连接数，因为nginx对app是用的异步传输，所以这个环节的连接速度很快，所以堆积的连接就很少。假如nginx对app服务器之间的带宽出了问题或是app服务器有问题，那么可能使连接堆积起来，这时可以通过设定nginx的代理超时时间，来使连接尽快释放掉，一般来说极少能用到28232个连接。
 
因为有软件使用了40000端口监听，常常出错的话，可以通过设定ip_local_port_range的最小值来解决：
 
echo "40001 61000" > /proc/sys/net/ipv4/ip_local_port_range
 
但是这么做很显然把系统可用端口数减少了，这时可以把ip_local_port_range的最大值往上调，但是好习惯是使用不超过32768的端口来侦听服务，另外也不必要去修改ip_local_port_range数值成1024 65535之类的，意义不大。
 
因为使用了nginx代理，在windows下也会造成大量TIME_WAIT，当然windows也可以调整：
 
在注册表（regedit）的HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters上添加一个DWORD类型的值TcpTimedWaitDelay，值就是秒数，即可。
 
windows默认是重用TIME_WAIT，我现在还不知道怎么改成不重用的，本地端口也没查到是什么值，但这些都关系不大，都可以按系统默认运作。
------------------------------------------------------------------------------------------------------------------------
TIME_WAIT状态
根据TCP协议，主动发起关闭的一方，会进入TIME_WAIT状态，持续2*MSL(Max Segment Lifetime)，缺省为240秒，在这个post中简洁的介绍了为什么需要这个状态。
值得一说的是，对于基于TCP的HTTP协议，关闭TCP连接的是Server端，这样，Server端会进入TIME_WAIT状态，可想而知，对于访问量大的Web Server，会存在大量的TIME_WAIT状态，假如server一秒钟接收1000个请求，那么就会积压240*1000=240，000个TIME_WAIT的记录，维护这些状态给Server带来负担。当然现代操作系统都会用快速的查找算法来管理这些TIME_WAIT，所以对于新的TCP连接请求，判断是否hit中一个TIME_WAIT不会太费时间，但是有这么多状态要维护总是不好。
HTTP协议1.1版规定default行为是Keep-Alive，也就是会重用TCP连接传输多个request/response，一个主要原因就是发现了这个问题。还有一个方法减缓TIME_WAIT压力就是把系统的2*MSL时间减少，因为240秒的时间实在是忒长了点，对于Windows，修改注册表，在HKEY_LOCAL_MACHINE\ SYSTEM\CurrentControlSet\Services\ Tcpip\Parameters上添加一个DWORD类型的值TcpTimedWaitDelay，一般认为不要少于60，不然可能会有麻烦。
对于大型的服务，一台server搞不定，需要一个LB(Load Balancer)把流量分配到若干后端服务器上，如果这个LB是以NAT方式工作的话，可能会带来问题。假如所有从LB到后端Server的IP包的source address都是一样的(LB的对内地址），那么LB到后端Server的TCP连接会受限制，因为频繁的TCP连接建立和关闭，会在server上留下TIME_WAIT状态，而且这些状态对应的remote address都是LB的，LB的source port撑死也就60000多个(2^16=65536,1~1023是保留端口，还有一些其他端口缺省也不会用），每个LB上的端口一旦进入Server的TIME_WAIT黑名单，就有240秒不能再用来建立和Server的连接，这样LB和Server最多也就能支持300个左右的连接。如果没有LB，不会有这个问题，因为这样server看到的remote address是internet上广阔无垠的集合，对每个address，60000多个port实在是够用了。
一开始我觉得用上LB会很大程度上限制TCP的连接数，但是实验表明没这回事，LB后面的一台Windows Server 2003每秒处理请求数照样达到了600个，难道TIME_WAIT状态没起作用？用Net Monitor和netstat观察后发现，Server和LB的XXXX端口之间的连接进入TIME_WAIT状态后，再来一个LB的XXXX端口的SYN包，Server照样接收处理了，而是想像的那样被drop掉了。翻书，从书堆里面找出覆满尘土的大学时代买的《UNIX Network Programming, Volume 1, Second Edition: Networking APIs: Sockets and XTI》，中间提到一句，对于BSD-derived实现，只要SYN的sequence number比上一次关闭时的最大sequence number还要大，那么TIME_WAIT状态一样接受这个SYN，难不成Windows也算BSD-derived?有了这点线索和关键字(BSD)，找到这个post，在NT4.0的时候，还是和BSD-derived不一样的，不过Windows Server 2003已经是NT5.2了，也许有点差别了。
做个试验，用Socket API编一个Client端，每次都Bind到本地一个端口比如2345，重复的建立TCP连接往一个Server发送Keep-Alive=false的HTTP请求，Windows的实现让sequence number不断的增长，所以虽然Server对于Client的2345端口连接保持TIME_WAIT状态，但是总是能够接受新的请求，不会拒绝。那如果SYN的Sequence Number变小会怎么样呢？同样用Socket API，不过这次用Raw IP，发送一个小sequence number的SYN包过去，Net Monitor里面看到，这个SYN被Server接收后如泥牛如海，一点反应没有，被drop掉了。
按照书上的说法，BSD-derived和Windows Server 2003的做法有安全隐患，不过至少这样至少不会出现TIME_WAIT阻止TCP请求的问题，当然，客户端要配合，保证不同TCP连接的sequence number要上涨不要下降。
----------------------------------------------------------------------------------------------------------------------------
Socket中的TIME_WAIT状态
在高并发短连接的server端，当server处理完client的请求后立刻closesocket此时会出现time_wait状态然后如果client再并发2000个连接，此时部分连接就连接不上了,用linger强制关闭可以解决此问题，但是linger会导致数据丢失，linger值为0时是强制关闭,无论并发多少多能正常连接上,如果非0会发生部分连接不上的情况!（可调用setsockopt设置套接字的linger延时标志，同时将延时时间设置为0。）
TCP/IP的RFC文档。TIME_WAIT是TCP连接断开时必定会出现的状态。
是无法避免掉的，这是TCP协议实现的一部分。
在WINDOWS下，可以修改注册表让这个时间变短一些
 
time_wait的时间为2msl,默认为4min.
你可以通过改变这个变量:
TcpTimedWaitDelay 
把它缩短到30s
TCP要保证在所有可能的情况下使得所有的数据都能够被投递。当你关闭一个socket时，主动关闭一端的socket将进入TIME_WAIT状态，而被动关闭一方则转入CLOSED状态，这的确能够保证所有的数据都被传输。当一个socket关闭的时候，是通过两端互发信息的四次握手过程完成的，当一端调用close()时，就说明本端没有数据再要发送了。这好似看来在握手完成以后，socket就都应该处于关闭CLOSED状态了。但这有两个问题，首先，我们没有任何机制保证最后的一个ACK能够正常传输，第二，网络上仍然有可能有残余的数据包(wandering duplicates)，我们也必须能够正常处理。
通过正确的状态机，我们知道双方的关闭过程如下
 
图
假设最后一个ACK丢失了，服务器会重发它发送的最后一个FIN，所以客户端必须维持一个状态信息，以便能够重发ACK；如果不维持这种状态，客户端在接收到FIN后将会响应一个RST，服务器端接收到RST后会认为这是一个错误。如果TCP协议能够正常完成必要的操作而终止双方的数据流传输，就必须完全正确的传输四次握手的四个节，不能有任何的丢失。这就是为什么socket在关闭后，仍然处于 TIME_WAIT状态，因为他要等待以便重发ACK。
如果目前连接的通信双方都已经调用了close()，假定双方都到达CLOSED状态，而没有TIME_WAIT状态时，就会出现如下的情况。现在有一个新的连接被建立起来，使用的IP地址与端口与先前的完全相同，后建立的连接又称作是原先连接的一个化身。还假定原先的连接中有数据报残存于网络之中，这样新的连接收到的数据报中有可能是先前连接的数据报。为了防止这一点，TCP不允许从处于TIME_WAIT状态的socket建立一个连接。处于TIME_WAIT状态的socket在等待两倍的MSL时间以后（之所以是两倍的MSL，是由于MSL是一个数据报在网络中单向发出到认定丢失的时间，一个数据报有可能在发送图中或是其响应过程中成为残余数据报，确认一个数据报及其响应的丢弃的需要两倍的MSL），将会转变为CLOSED状态。这就意味着，一个成功建立的连接，必然使得先前网络中残余的数据报都丢失了。
由于TIME_WAIT状态所带来的相关问题，我们可以通过设置SO_LINGER标志来避免socket进入TIME_WAIT状态，这可以通过发送RST而取代正常的TCP四次握手的终止方式。但这并不是一个很好的主意，TIME_WAIT对于我们来说往往是有利的。
客户端与服务器端建立TCP/IP连接后关闭SOCKET后，服务器端连接的端口
状态为TIME_WAIT
是不是所有执行主动关闭的socket都会进入TIME_WAIT状态呢？
有没有什么情况使主动关闭的socket直接进入CLOSED状态呢？
主动关闭的一方在发送最后一个 ack 后
就会进入 TIME_WAIT 状态 停留2MSL（max segment lifetime）时间
这个是TCP/IP必不可少的，也就是“解决”不了的。
 
也就是TCP/IP设计者本来是这么设计的
主要有两个原因
1。防止上一次连接中的包，迷路后重新出现，影响新连接
   （经过2MSL，上一次连接中所有的重复包都会消失）
2。可靠的关闭TCP连接
   在主动关闭方发送的最后一个 ack(fin) ，有可能丢失，这时被动方会重新发
   fin, 如果这时主动方处于 CLOSED 状态 ，就会响应 rst 而不是 ack。所以
   主动方要处于 TIME_WAIT 状态，而不能是 CLOSED 。
 
TIME_WAIT 并不会占用很大资源的，除非受到攻击。
 
还有，如果一方 send 或 recv 超时，就会直接进入 CLOSED 状态
socket-faq中的这一段讲的也很好，摘录如下：
2.7. Please explain the TIME_WAIT state.
```

connect会阻塞，怎么解决?(必考必问)

```
最通常的方法最有效的是加定时器；也可以采用非阻塞模式。
 
设置非阻塞，返回之后用select检测状态)
```

如果select返回可读，结果只读到0字节，什么情况？

```
某个套接字集合中没有准备好，可能会select内存用FD_CLR清该位为0；
```

socket什么情况下可读？

```
每次读操作返回前都要检查是否还有剩余数据没读完，如果是的话保持数据有效标志，不这样设计的话会出现明显的不一致，那就是数据在读缓冲但没有读有效标志。
```

keepalive是什么

```
设置Keepalive参数，检测已中断的客户连接
在TCP中有一个Keep-alive的机制可以检测死连接，原理很简单，TCP会在空闲了一定时间后发送数据给对方：
1.如果主机可达，对方就会响应ACK应答，就认为是存活的。
2.如果可达，但应用程序退出，对方就发RST应答，发送TCP撤消连接。
3.如果可达，但应用程序崩溃，对方就发FIN消息。
4.如果对方主机不响应ack, rst，继续发送直到超时，就撤消连接。这个时间就是默认的二个小时。
```

UDP中使用connect的好处:

```
1:会提升效率.前面已经描述了.2:高并发服务中会增加系统稳定性.原因:假设client A 通过非connect的UDP与serverB,C通信.B,C提供相同服务.为了负载均衡,我们让A与B,C交替通信.A 与 B通信IPa:PORTa<----> IPb:PORTbA 与 C通信IPa:PORTa'<---->IPc:PORTc 
假设PORTa 与 PORTa'相同了(在大并发情况下会发生这种情况),那么就有可能出现A等待B的报文,却收到了C的报文.导致收报错误.解决方法内就是采用connect的UDP通信方式.在A中创建两个udp,然后分别connect到B,C.
```

```
ping
命令所利用的原理是这样的:网络上的机器都有唯一确定的IP地址，我们给目标IP地址发送一个数据包，对方就要返回一个同样大小的数据包，根据返回的数据包我们可以确定目标主机的存在，可以初步判断目标主机的操作系统等。
```





 

 

 

文件描述符（fd：file descriptor）：

每个文件进程控制块中都有一份文件描述符表（可以把它看成是一个数组，里面的元素是指向file结构体指针类型），这个数组的下标就是文件描述符。

 

select()和poll() IO多路复用模型

select的缺点：

 

单个进程能够监视的文件描述符的数量存在最大限制，通常是1024，当然可以更改数量，但由于select采用轮询的方式扫描文件描述符，文件描述符数量越多，性能越差；(在linux内核头文件中，有这样的定义：#define __FD_SETSIZE    1024)

内核 / 用户空间内存拷贝问题，select需要复制大量的句柄数据结构，产生巨大的开销；

select返回的是含有整个句柄的数组，应用程序需要遍历整个数组才能发现哪些句柄发生了事件；

select的触发方式是水平触发，应用程序如果没有完成对一个已经就绪的文件描述符进行IO操作，那么之后每次select调用还是会将这些文件描述符通知进程。

相比select模型，poll使用链表保存文件描述符，因此没有了监视文件数量的限制，但其他三个缺点依然存在。

 

拿select模型为例，假设我们的服务器需要支持100万的并发连接，则在__FD_SETSIZE 为1024的情况下，则我们至少需要开辟1k个进程才能实现100万的并发连接。除了进程间上下文切换的时间消耗外，从内核/用户空间大量的无脑内存拷贝、数组轮询等，是系统难以承受的。因此，基于select模型的服务器程序，要达到10万级别的并发访问，是一个很难完成的任务。

 

设想一下如下场景：有100万个客户端同时与一个服务器进程保持着TCP连接。而每一时刻，通常只有几百上千个TCP连接是活跃的(事实上大部分场景都是这种情况)。如何实现这样的高并发？

 

在select/poll时代，服务器进程每次都把这100万个连接告诉操作系统(从用户态复制句柄数据结构到内核态)，让操作系统内核去查询这些套接字上是否有事件发生，轮询完后，再将句柄数据复制到用户态，让服务器应用程序轮询处理已发生的网络事件，这一过程资源消耗较大，因此，select/poll一般只能处理几千的并发连接。

epoll的设计和实现与select完全不同。epoll通过在Linux内核中申请一个简易的文件系统(文件系统一般用什么数据结构实现？B+树)。把原先的select/poll调用分成了3个部分：

 

1）调用epoll_create()建立一个epoll对象(在epoll文件系统中为这个句柄对象分配资源)

 

2）调用epoll_ctl向epoll对象中添加这100万个连接的套接字

 

3）调用epoll_wait收集发生的事件的连接

如此一来，要实现上面说是的场景，只需要在进程启动时建立一个epoll对象，然后在需要的时候向这个epoll对象中添加或者删除连接。同时，epoll_wait的效率也非常高，因为调用epoll_wait时，并没有一股脑的向操作系统复制这100万个连接的句柄数据，内核也不需要去遍历全部的连接。

 

 

(1)select==>时间复杂度O(n)

它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以**select具有O(n)的无差别轮询复杂度**，同时处理的流越多，无差别轮询时间就越长。

(2)poll==>时间复杂度O(n)

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， **但是它没有最大连接数的限制**，原因是它是基于链表来存储的.

(3)epoll==>时间复杂度O(1)

**epoll****可以理解为event poll**，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是**事件驱动（每个事件关联上fd）**的，此时我们对这些流的操作都是有意义的。**（复杂度降低到了O(1)）**

select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。**但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的**，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。  

 

 

**select****：**

select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是：

1、 单个进程可监视的fd数量被限制，即能监听端口的大小有限。

​      一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048.

2、 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低：

​       当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。

3、需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大

**poll****：**

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。

**它没有最大连接数的限制**，原因是它是基于链表来存储的，但是同样有一个缺点：

1、大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。                   

2、poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。

**epoll:**

epoll有EPOLLLT和EPOLLET两种触发模式，LT是默认的模式，ET是“高速”模式。LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作，而在ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无 论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读光，也就是说一直读到read的返回值小于请求值，或者 遇到EAGAIN错误。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。

**epoll****为什么要有****EPOLLET****触发模式？**

如果采用EPOLLLT模式的话，系统中一旦有大量你不需要读写的就绪文件描述符，它们每次调用epoll_wait都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率.。而采用EPOLLET这种边沿触发模式的话，当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你！！！**这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符**

**epoll****的优点：**

1、**没有最大并发连接的限制，能打开的****FD****的上限远大于****1024****（****1G****的内存上能监听约****10****万个端口）**；
 **2****、效率提升，不是轮询的方式，不会随着****FD****数目的增加效率下降。只有活跃可用的****FD****才会调用****callback****函数；**
 **即****Epoll****最大的优点就在于它只管你****“****活跃****”****的连接，而跟连接总数无关，因此在实际的网络环境中，****Epoll****的效率就会远远高于****select****和****poll****。**

3、 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。

 

 

句柄：IO事件，信号和定时事件统称为事件源。一个时间通常和句柄绑在一起，句柄的作用是当内核检测到某一事件就绪后，通过句柄通知应用程序。对于IO事件，句柄就是文件描述符。

 

 

Ppid：父进程ID

 

**常用端口号大全**

代理服务器常用以下端口：

（1）. HTTP协议代理服务器常用端口号：80/8080/3128/8081/9080

（2）. SOCKS代理协议服务器常用端口号：1080

（3）. FTP（文件传输）协议代理服务器常用端口号：21

（4）. Telnet（远程登录）协议代理服务器常用端口：23

**HTTP**服务器，默认的端口号为80/tcp（木马Executor开放此端口）；

**HTTPS**（securely transferring web pages）服务器，默认的端口号为443/tcp 443/udp；

**Telnet**（不安全的文本传送），默认端口号为23/tcp（木马Tiny Telnet Server所开放的端口）；

**FTP**，默认的端口号为21/tcp（木马Doly Trojan、Fore、Invisible FTP、WebEx、WinCrash和Blade Runner所开放的端口）；

**TFTP**（Trivial File Transfer Protocol ），默认的端口号为69/udp；

**SSH**（安全登录）、SCP（文件传输）、端口重定向，默认的端口号为22/tcp；

 

