---
typora-copy-images-to: ./
---

### 进程与线程的概念，区别，通信，同步，系统调用，多线程和多进程的不同 ，多进程和多线程的使用场景 ，线程模型

进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的
并发；
线程是进程的子任务，是CPU 调度和分派的基本单位，用于保证程序的实时性，实现进程内
部的并发；线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：
独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间
（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。

区别：
1.一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖
于进程而存在。
2.进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。（资源分配给进程，
同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），
数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫
运行时段，用来存放所有局部变量和临时变量。）
3.进程是资源分配的最小单位，线程是CPU 调度的最小单位；
4.系统开销： 由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I
／o 设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，
在进行进程切换时，涉及到整个当前进程CPU 环境的保存以及新被调度运行的进程的CPU 环境的
设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，
进程切换的开销也远大于线程切换的开销。
5.通信：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实
现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行
通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、
同步和通信都无须操作系统内核的干预
6.进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，
但是编程调试相对复杂。
7.进程间不会相互影响；线程一个线程挂掉将导致整个进程挂掉

8.进程适应于多核、多机分布；线程适用于多核
进程间通信的方式：
进程间通信主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及
套接字socket。
1.管道：
管道主要包括无名管道和命名管道:管道可用于具有亲缘关系的父子进程间的通信，有名管
道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信
1.1 普通管道PIPE：
1)它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端
2)它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）
3)它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但
是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。
1.2 命名管道FIFO：
1)FIFO 可以在无关的进程之间交换数据
2)FIFO 有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。

2. 系统IPC：
    2.1 消息队列
    消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来
    标记。(消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特
    点)具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进
    程则可以从消息队列中读取信息；
    特点：
    1)消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。
    2)消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。
    3)消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息
    的类型读取。
    2.2 信号量semaphore

  信号量（semaphore）与已经介绍过的IPC 结构不同，它是一个计数器，可以用来控制多个
  进程对共享资源的访问。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。
  特点：
  1)信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。
  2)信号量基于操作系统的PV 操作，程序对信号量的操作都是原子操作。
  3)每次对信号量的PV 操作不仅限于对信号量值加1 或减1，而且可以加减任意正整数。
  4)支持信号量组。

  2.3 信号signal
  信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
  2.4 共享内存（Shared Memory）
  它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中
  数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等
  特点：
  1)共享内存是最快的一种IPC，因为进程是直接对内存进行存取
  2)因为多个进程可以同时操作，所以需要进行同步
  3)信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问
  3.套接字SOCKET：
  socket 也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机之间的进
  程通信。

  

  线程间通信的方式:
  临界区：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；
  互斥量Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资
  源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问

  信号量Semphare：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻
  去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。
  事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多
  线程优先级的比较操作



系统调用：

信号量
信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作：
P(SV):如果信号量SV 大于0，将它减一；如果SV 值为0，则挂起该线程。
V(SV)：如果有其他进程因为等待SV 而挂起，则唤醒，然后将SV+1；否则直接将SV+1。
其系统调用为：
sem_wait（sem_t *sem）：以原子操作的方式将信号量减1，如果信号量值为0，则sem_wait
将被阻塞，直到这个信号量具有非0 值。
sem_post（sem_t *sem)：以原子操作将信号量值+1。当信号量大于0 时，其他正在调用
sem_wait 等待信号量的线程将被唤醒。



互斥量
互斥量又称互斥锁，主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。
当进入临界区时，需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，
以唤醒其他等待该互斥锁的线程。其主要的系统调用如下：
pthread_mutex_init:初始化互斥锁
pthread_mutex_destroy：销毁互斥锁
pthread_mutex_lock：以原子操作的方式给一个互斥锁加锁，如果目标互斥锁已经被上锁，
pthread_mutex_lock 调用将阻塞，直到该互斥锁的占有者将其解锁。
pthread_mutex_unlock:以一个原子操作的方式给一个互斥锁解锁。



条件变量
条件变量，又称条件锁，用于在线程之间同步共享数据的值。条件变量提供一种线程间通
信机制：当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。即，当某个
共享变量等于某个值时，调用signal/broadcast。此时操作共享变量时需要加锁。其主要的系
统调用如下：

pthread_cond_init:初始化条件变量
pthread_cond_destroy：销毁条件变量
pthread_cond_signal：唤醒一个等待目标条件变量的线程。哪个线程被唤醒取决于调度策
略和优先级。
pthread_cond_wait：等待目标条件变量。需要一个加锁的互斥锁确保操作的原子性。该函
数中在进入wait 状态前首先进行解锁，然后接收到信号后会再加锁，保证该线程对共享资源正
确访问。

### 有了进程为什么还需要线程

线程产生的原因：
进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量；但是其具有一些缺
点：
进程在同一时间只能干一件事
进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资
源，仍然不会执行。

因此，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在
并发执行时所付出的时空开销，提高并发性。和进程相比，线程的优势如下：
从资源上来讲，线程是一种非常"节俭"的多任务操作方式。在linux 系统下，启动一个新的
进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这
是一种"昂贵"的多任务工作方式。
从切换效率上来讲，运行于一个进程中的多个线程，它们之间使用相同的地址空间，而且线
程间彼此切换所需时间也远远小于进程间切换所需要的时间。据统计，一个进程的开销大约是一
个线程开销的30 倍左右。（
从通信机制上来讲，线程间方便的通信机制。对不同进程来说，它们具有独立的数据空间，
要进行数据的传递只能通过进程间通信的方式进行，这种方式不仅费时，而且很不方便。线程则
不然，由于同一进城下的线程之间贡献数据空间，所以一个线程的数据可以直接为其他线程所用，
这不仅快捷，而且方便。
除以上优点外，多线程程序作为一种多任务、并发的工作方式，还有如下优点：
1、使多CPU 系统更加有效。操作系统会保证当线程数不大于CPU 数目时，不同的线程运行
于不同的CPU 上。
2、改善程序结构。一个既长又复杂的进程可以考虑分为多个线程，成为几个独立或半独立
的运行部分，这样的程序才会利于理解和修改。

### 多线程和多进程的不同

进程是资源分配的最小单位，而线程时CPU 调度的最小单位。多线程之间共享同一个进程的
地址空间，线程间通信简单，同步复杂，线程创建、销毁和切换简单，速度快，占用内存少，适
用于多核分布式系统，但是线程间会相互影响，一个线程意外终止会导致同一个进程的其他线程
也终止，程序可靠性弱。而多进程间拥有各自独立的运行地址空间，进程间不会相互影响，程序
可靠性强，但是进程创建、销毁和切换复杂，速度慢，占用内存多，进程间通信复杂，但是同步
简单，适用于多核、多机分布。



多进程模型的优势是CPU
多线程模型主要优势为线程间切换代价较小，因此适用于I/O 密集型的工作场景，因此I/O
密集型的工作场景经常会由于I/O 阻塞导致频繁的切换线程。同时，多线程模型也适用于单机多
核分布式场景。
多进程模型，适用于CPU 密集型。同时，多进程模型也适用于多机分布式场景中，易于多机
扩展。

### 互斥锁（**mutex）机制**，**以及**互斥锁和读写锁的区别 

1、互斥锁和读写锁区别：
互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败
时，线程会进入睡眠，等待锁释放时被唤醒。
读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但
是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写
锁释放时被唤醒。注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能
被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。
适用于读取数据的频率远远大于写数据的频率的场合。
互斥锁和读写锁的区别：
1）读写锁区分读者和写者，而互斥锁不区分
2）互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个
写者，但是允许多个读者同时读对象。
2、Linux 的4 种锁机制：

互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败
时，线程会进入睡眠，等待锁释放时被唤醒
读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但
是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写
锁释放时被唤醒。注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能
被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。
适用于读取数据的频率远远大于写数据的频率的场合。
自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，
不会进入睡眠，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的
消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU
资源。
RCU：即read-copy-update，在修改数据时，首先需要读取数据，然后生成一个副本，对副
本进行修改。修改完成后，再将老数据update 成新的数据。使用RCU 时，读者几乎不需要同步
开销，既不需要获得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而
对于写者的同步开销较大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修
改操作。在有大量读操作，少量写操作的情况下效率非常高。

### 进程状态转换图，动态就绪，静态就绪，动态阻塞，静态阻塞（28题）

### 进程死锁发生的条件以及如何解决死锁 

死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的下相互等待的现象。死锁
发生的四个必要条件如下：
互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，
直至占有该资源的进程使用完成后释放该资源；
请求和保持条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他
进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源
不可剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释
放
环路等待条件：进程发生死锁后，必然存在一个进程-资源之间的环形链
解决死锁的方法即破坏上述四个条件之一，主要方法如下：
资源一次性分配，从而剥夺请求和保持条件
可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条
件
资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则
相反，从而破坏环路等待的条件

### 线程需要保存哪些上下文，SP、PC、EAX这些寄存器是干嘛用的 

线程在切换的过程中需要保存当前线程Id、线程状态、堆栈、寄存器状态等信息。其中寄
存器主要包括SP PC EAX 等寄存器，其主要功能如下：
SP:堆栈指针，指向当前栈的栈顶地址

PC:程序计数器，存储下一条将要执行的指令
EAX:累加寄存器，用于加法乘法的缺省寄存器

### 游戏服务器应该为每个用户开辟一个线程还是一个进程，为什么？

游戏服务器应该为每个用户开辟一个进程。因为同一进程间的线程会相互影响，一个线程死
掉会影响其他线程，从而导致进程崩溃。因此为了保证不同用户之间不会相互影响，应该为每个
用户开辟一个进程

### 就绪状态的进程在等待什么

被调度使用cpu 的运行权

### 用过哪些锁，各种锁的机制介绍

同步的时候用一个互斥量，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量
上的锁。对互斥量进行加锁以后，任何其他试图再次对互斥量加锁的线程将会被阻塞直到当前线
程释放该互斥锁。如果释放互斥锁时有多个线程阻塞，所有在该互斥锁上的阻塞线程都会变成可
运行状态，第一个变为运行状态的线程可以对互斥量加锁，其他线程将会看到互斥锁依然被锁住，
只能回去再次等待它重新变为可用。在这种方式下，每次只有一个线程可以向前执行。



锁包括互斥锁，条件变量，自旋锁和读写锁

生产者消费者问题利用互斥锁和条件变量可以很容易解决，条件变量这里起到了替代信号量
的作用

### 两个进程访问临界区资源，会不会出现都获得自旋锁的情况

单核cpu，并且开了抢占可以造成这种情况。

### 孤儿进程和僵尸进程，危害和解决

1）正常进程
正常情况下，子进程是通过父进程创建的，子进程再创建新的进程。子进程的结束和父进程的运
行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。当一个进程完成它的工
作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。
unix 提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到：在每
个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。但是仍然
为其保留一定的信息，直到父进程通过wait / waitpid 来取时才释放。保存信息包括：
1 进程号the process ID
2 退出状态the termination status of the process
3 运行时间the amount of CPU time taken by the process 等

2）孤儿进程
一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进
程将被init 进程(进程号为1)所收养，并由init 进程对它们完成状态收集工作。
3）僵尸进程
一个进程使用fork 创建子进程，如果子进程退出，而父进程并没有调用wait 或waitpid 获取子
进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。
僵尸进程是一个进程必然会经过的过程：这是每个子进程在结束时都要经过的阶段。
如果子进程在exit()之后，父进程没有来得及处理，这时用ps 命令就能看到子进程的状态是“Z”。
如果父进程能及时处理，可能用ps 命令就来不及看到子进程的僵尸状态，但这并不等于子进程
不经过僵尸状态。
如果父进程在子进程结束之前退出，则子进程将由init 接管。init 将会以父进程的身份对僵尸
状态的子进程进行处理。

危害：
如果进程不调用wait / waitpid 的话， 那么保留的那段信息就不会释放，其进程号就会一直被
占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程
号而导致系统不能产生新的进程。
外部消灭：
通过kill 发送SIGTERM 或者SIGKILL 信号消灭产生僵尸进程的进程，它产生的僵死进程就变成
了孤儿进程，这些孤儿进程会被init 进程接管，init 进程会wait()这些孤儿进程，释放它们占
用的系统进程表中的资源
内部解决：
1、子进程退出时向父进程发送SIGCHILD 信号，父进程处理SIGCHILD 信号。在信号处理函数中
调用wait 进行处理僵尸进程。
2、fork 两次，原理是将子进程成为孤儿进程，从而其的父进程变为init 进程，通过init 进程
可以处理僵尸进程。

### 5种IO模型

阻塞非阻塞信号驱动IO、IO多路转接、异步IO

1.阻塞IO:调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的去检查这个函
数有没有返回，必须等这个函数返回才能进行下一步动作
2.非阻塞IO:非阻塞等待，每隔一段时间就去检测IO 事件是否就绪。没有就绪就可以做其他事。
3.信号驱动IO:信号驱动IO:linux 用套接口进行信号驱动IO，安装一个信号处理函数，进程继
续运行并不阻塞，当IO 时间就绪，进程收到SIGIO 信号。然后处理IO 事件。
4.IO 复用/多路转接IO:linux 用select/poll 函数实现IO 复用模型，这两个函数也会使进程阻
塞，但是和阻塞IO 所不同的是这两个函数可以同时阻塞多个IO 操作。而且可以同时对多个读操
作、写操作的IO 函数进行检测。知道有数据可读或可写时，才真正调用IO 操作函数
5.异步IO:linux 中，可以调用aio_read 函数告诉内核描述字缓冲区指针和缓冲区的大小、文件
偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。

### 什么是内核态和用户态，操作系统为什么要分内核态和用户态，转化原理

用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同。用户态拥有
最低的特权级，内核态拥有较高的特权级。运行在用户态的程序不能直接访问操作系统内核数据
结构和程序。内核态和用户态之间的转换方式主要包括：系统调用，异常和中断。



为了安全性。在cpu 的一些指令中，有的指令如果用错，将会导致整个系统崩溃。分了内核态和
用户态后，当用户需要操作这些指令时候，内核为其提供了API，可以通过系统调用陷入内核，
让内核去执行这些操作。



1）用户态切换到内核态的3 种方式
1、系统调用
这是用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提
供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中
断来实现，例如Linux 的ine 80h 中断。
2、异常
当CPU 在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前
运行进程切换到处理此。异常的内核相关程序中，也就到了内核态，比如缺页异常。
3、外围设备的中断
当外围设备完成用户请求的操作之后，会向CPU 发出相应的中断信号，这时CPU 会暂停执
行下一条将要执行的指令，转而去执行中断信号的处理程序，如果先执行的指令是用户态下的程
序，那么这个转换的过程自然也就发生了有用户态到内核态的切换。比如硬盘读写操作完成，系
统会切换到硬盘读写的中断处理程序中执行后续操作等。

2）切换操作
从出发方式看，可以在认为存在前述3 种不同的类型，但是从最终实际完成由用户态到内
核态的切换操作上来说，涉及的关键步骤是完全一样的，没有任何区别，都相当于执行了一个中
断响应的过程，因为系统调用实际上最终是中断机制实现的，而异常和中断处理机制基本上是一
样的，用户态切换到内核态的步骤主要包括：
1、从当前进程的描述符中提取其内核栈的ss0 及esp0 信息。
2、使用ss0 和esp0 指向的内核栈将当前进程的cs,eip，eflags，ss,esp 信息保存起来，
这个过程也完成了由用户栈找到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。
3、将先前由中断向量检索得到的中断处理程序的cs，eip 信息装入相应的寄存器，开始执
行中断处理程序，这时就转到了内核态的程序执行了。

### 怎样确定当前线程是繁忙还是阻塞

使用ps命令查看

### 空闲的进程和阻塞的进程状态会不会在唤醒的时候误判

### 内存溢出和内存泄漏

1、内存溢出
指程序申请内存时，没有足够的内存供申请者使用。内存溢出就是你要的内存空间超过了系统实
际分配给你的空间，此时系统相当于没法满足你的需求，就会报内存溢出的错误
内存溢出原因：
内存中加载的数据量过于庞大，如一次从数据库取出过多数据
集合类中有对对象的引用，使用完后未清空，使得不能回收
代码中存在死循环或循环产生过多重复的对象实体
使用的第三方软件中的BUG
启动参数内存值设定的过小
2、内存泄漏

内存泄漏是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内
存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，
因而造成了内存的浪费。
内存泄漏的分类：
1、堆内存泄漏（Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc new
等从堆中分配的一块内存，再是完成后必须通过调用对应的free 或者delete 删掉。如果程序
的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。
2、系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如Bitmap,handle ,SOCKET
等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳
定。
3、没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不
是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄
露。

### 常用线程模型

1、Future 模型
该模型通常在使用的时候需要结合Callable 接口配合使用。
Future 是把结果放在将来获取，当前主线程并不急于获取处理结果。允许子线程先进行处理一
段时间，处理结束之后就把结果保存下来，当主线程需要使用的时候再向子线程索取。
Callable 是类似于Runnable 的接口，其中call 方法类似于run 方法，所不同的是run 方
法不能抛出受检异常没有返回值，而call 方法则可以抛出受检异常并可设置返回值。两者的方
法体都是线程执行体。

2、fork&join 模型
该模型包含递归思想和回溯思想，递归用来拆分任务，回溯用合并结果。可以用来处理一
些可以进行拆分的大任务。其主要是把一个大任务逐级拆分为多个子任务，然后分别在子线程中
执行，当每个子线程执行结束之后逐级回溯，返回结果进行汇总合并，最终得出想要的结果。
这里模拟一个摘苹果的场景：有100 棵苹果树，每棵苹果树有10 个苹果，现在要把他们摘
下来。为了节约时间，规定每个线程最多只能摘10 棵苹树以便于节约时间。各个线程摘完之后
汇总计算总苹果树。
3、actor 模型
actor 模型属于一种基于消息传递机制并行任务处理思想，它以消息的形式来进行线程间数
据传输，避免了全局变量的使用，进而避免了数据同步错误的隐患。actor 在接受到消息之后可
以自己进行处理，也可以继续传递（分发）给其它actor 进行处理。在使用actor 模型的时候需
要使用第三方Akka 提供的框架。
4、生产者消费者模型
生产者消费者模型都比较熟悉，其核心是使用一个缓存来保存任务。开启一个/多个线程来
生产任务，然后再开启一个/多个来从缓存中取出任务进行处理。这样的好处是任务的生成和处
理分隔开，生产者不需要处理任务，只负责向生成任务然后保存到缓存。而消费者只需要从缓存
中取出任务进行处理。使用的时候可以根据任务的生成情况和处理情况开启不同的线程来处理。
比如，生成的任务速度较快，那么就可以灵活的多开启几个消费者线程进行处理，这样就可以避
免任务的处理响应缓慢的问题。

5、master-worker 模型

master-worker 模型类似于任务分发策略，开启一个master 线程接收任务，然后在master
中根据任务的具体情况进行分发给其它worker 子线程，然后由子线程处理任务。如需返回结果，
则worker 处理结束之后把处理结果返回给master。

### 系统调用是什么，你用过哪些系统调用

1）概念：
在计算机中，系统调用（英语：system call），又称为系统呼叫，指运行在使用者空间的
程序向操作系统内核请求需要更高权限运行的服务。系统调用提供了用户程序与操作系统之间的
接口（即系统调用是用户程序和内核交互的接口）。
操作系统中的状态分为管态（核心态）和目态（用户态）。大多数系统交互式操作需求在内
核态执行。如设备IO 操作或者进程间通信。特权指令：一类只能在核心态下运行而不能在用户
态下运行的特殊指令。不同的操作系统特权指令会有所差异，但是一般来说主要是和硬件相关的
一些指令。用户程序只在用户态下运行，有时需要访问系统核心功能，这时通过系统调用接口使
用系统调用。
应用程序有时会需要一些危险的、权限很高的指令，如果把这些权限放心地交给用户程序是
很危险的(比如一个进程可能修改另一个进程的内存区，导致其不能运行)，但是又不能完全不给
这些权限。于是有了系统调用，危险的指令被包装成系统调用，用户程序只能调用而无权自己运
行那些危险的指令。另外，计算机硬件的资源是有限的，为了更好的管理这些资源，所有的资源
都由操作系统控制，进程只能向操作系统请求这些资源。操作系统是这些资源的唯一入口，这个
入口就是系统调用。
2）系统调用举例：
对文件进行写操作，程序向打开的文件写入字符串“hello world”，open 和write 都是系
统调用。如下：
#include<stdio.h>

还有写数据write，创建进程fork，vfork 等都是系统调用。

### 手写**一下**fork调用示例，fork和vfork的区别 

fork 的基础知识：
fork:创建一个和当前进程映像一样的进程可以通过fork( )系统调用：
#include <sys/types.h>
#include <unistd.h>
pid_t fork(void);
成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进
程都会继续运行。在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程
的pid。如果出现错误，fork( )返回一个负值。
最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前
进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执
行文件的映像。这种“派生加执行”的方式是很常见的。
在早期的Unix 系统中，创建进程比较原始。当调用fork 时，内核会把所有的内部数据结构
复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空
间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix 系统采取了更多的优化，
例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。

2、fork 实例
int main(void)
{
pid_t pid;
signal(SIGCHLD, SIG_IGN);
printf("before fork pid:%d\n", getpid());
int abc = 10;
pid = fork();
if (pid == -1) { //错误返回
perror("tile");

return -1;
}
if (pid > 0) { //父进程空间
abc++;

printf("parent:pid:%d \n", getpid());
printf("abc:%d \n", abc);
sleep(20);
}
else if (pid == 0) { //子进程空间
abc++;
printf("child:%d,parent: %d\n", getpid(), getppid());
printf("abc:%d", abc);
}
printf("fork after...\n");
}



vfork 的基础知识：
在实现写时复制之前，Unix 的设计者们就一直很关注在fork 后立刻执行exec 所造成的地
址空间的浪费。BSD 的开发者们在3.0 的BSD 系统中引入了vfork( )系统调用。

#include <sys/types.h>
#include <unistd.h>
pid_t vfork(void);
除了子进程必须要立刻执行一次对exec 的系统调用，或者调用_exit( )退出，对vfork( )
的成功调用所产生的结果和fork( )是一样的。vfork( )会挂起父进程直到子进程终止或者运行
了一个新的可执行文件的映像。通过这样的方式，vfork( )避免了地址空间的按页复制。在这个
过程中，父进程和子进程共享相同的地址空间和页表项。实际上vfork( )只完成了一件事：复
制内部的内核数据结构。因此，子进程也就不能修改地址空间中的任何内存。
vfork( )是一个历史遗留产物，Linux 本不应该实现它。需要注意的是，即使增加了写时复
制，vfork( )也要比fork( )快，因为它没有进行页表项的复制。然而，写时复制的出现减少了
对于替换fork( )争论。实际上，直到2.2.0 内核，vfork( )只是一个封装过的fork( )。因为
对vfork( )的需求要小于fork( )，所以vfork( )的这种实现方式是可行的。

补充知识点：写时复制
Linux 采用了写时复制的方法，以减少fork 时对父进程空间进程整体复制带来的开销。
写时复制是一种采取了惰性优化方法来避免复制时的系统开销。它的前提很简单：如果有多
个进程要读取它们自己的那部门资源的副本，那么复制是不必要的。每个进程只要保存一个指向
这个资源的指针就可以了。只要没有进程要去修改自己的“副本”，就存在着这样的幻觉：每个
进程好像独占那个资源。从而就避免了复制带来的负担。如果一个进程要修改自己的那份资源“副
本”，那么就会复制那份资源，并把复制的那份提供给进程。不过其中的复制对进程来说是透明
的。这个进程就可以修改复制后的资源了，同时其他的进程仍然共享那份没有修改过的资源。所
以这就是名称的由来：在写入时进行复制。
写时复制的主要好处在于：如果进程从来就不需要修改资源，则不需要进行复制。惰性算法
的好处就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行。
在使用虚拟内存的情况下，写时复制（Copy-On-Write）是以页为基础进行的。所以，只要
进程不修改它全部的地址空间，那么就不必复制整个地址空间。在fork( )调用结束后，父进程
和子进程都相信它们有一个自己的地址空间，但实际上它们共享父进程的原始页，接下来这些页
又可以被其他的父进程或子进程共享。
写时复制在内核中的实现非常简单。与内核页相关的数据结构可以被标记为只读和写时复制。
如果有进程试图修改一个页，就会产生一个缺页中断。内核处理缺页中断的方式就是对该页进行
一次透明复制。这时会清除页面的COW 属性，表示着它不再被共享。
现代的计算机系统结构中都在内存管理单元（MMU）提供了硬件级别的写时复制支持，所以
实现是很容易的。

在调用fork( )时，写时复制是有很大优势的。因为大量的fork 之后都会跟着执行exec，
那么复制整个父进程地址空间中的内容到子进程的地址空间完全是在浪费时间：如果子进程立刻

执行一个新的二进制可执行文件的映像，它先前的地址空间就会被交换出去。写时复制可以对这
种情况进行优化。
fork 和vfork 的区别：
1. fork( )的子进程拷贝父进程的数据段和代码段；vfork( )的子进程与父进程共享数据段
2. fork( )的父子进程的执行次序不确定；vfork( )保证子进程先运行，在调用exec 或exit
    之前与父进程数据是共享的，在它调用exec 或exit 之后父进程才可能被调度运行。
3. vfork( )保证子进程先运行，在它调用exec 或exit 之后父进程才可能被调度运行。如
    果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。
    4.当需要改变共享数据段中变量的值，则拷贝父进程。



### 为什么要有page cache，操作系统怎么设计的page cache

加快从磁盘读取文件的速率。page cache 中有一部分磁盘文件的缓存，因为从磁盘中读取文件
比较慢，所以读取文件先去page cache 中去查找，如果命中，则不需要去磁盘中读取，大大加
快读取速度。在Linux 内核中，文件的每个数据块最多只能对应一个Page Cache 项，它通过
两个数据结构来管理这些Cache
项，一个是radix tree，另一个是双向链表。Radix tree 是一种搜索树，Linux
内核利用这个数据结构来通过文件内偏移快速定位Cache 项

### server端监听端口，但还没客户端连接进来，此时进程什么状态？

这个需要看服务端的编程模型，如果如上一个问题的回答描述的这样，则处于阻塞状态，如果使
用了epoll,select 等这样的io 复用情况下，处于运行状态



### 操作系统中的程序的内存结构 

![6](C:\Users\yuhexue\Desktop\6.png)





一个程序本质上都是由BSS 段、data 段、text 段三个组成的。可以看到一个可执行程序在
存储（没有调入内存）时分为代码段、数据区和未初始化数据区三部分。
BSS 段（未初始化数据区）：通常用来存放程序中未初始化的全局变量和静态变量的一块内
存区域。BSS 段属于静态分配，程序结束后静态变量资源由系统自动释放。
数据段：存放程序中已初始化的全局变量的一块内存区域。数据段也属于静态内存分配

代码段：存放程序执行代码的一块内存区域。这部分区域的大小在程序运行前就已经确定，
并且内存区域属于只读。在代码段中，也有可能包含一些只读的常数变量
text 段和data 段在编译时已经分配了空间，而BSS 段并不占用可执行文件的大小，它是由
链接器来获取内存的。
bss 段（未进行初始化的数据）的内容并不存放在磁盘上的程序文件中。其原因是内核在程
序开始运行前将它们设置为0。需要存放在程序文件中的只有正文段和初始化数据段。
data 段（已经初始化的数据）则为数据分配空间，数据保存到目标文件中。
数据段包含经过初始化的全局变量以及它们的值。BSS 段的大小从可执行文件中得到，然后
链接器得到这个大小的内存块，紧跟在数据段的后面。当这个内存进入程序的地址空间后全部清
零。包含数据段和BSS 段的整个区段此时通常称为数据区。

可执行程序在运行时又多出两个区域：栈区和堆区。
栈区：由编译器自动释放，存放函数的参数值、局部变量等。每当一个函数被调用时，该
函数的返回类型和一些调用的信息被存放到栈中。然后这个被调用的函数再为他的自动变量和
临时变量在栈上分配空间。每调用一个函数一个新的栈就会被使用。栈区是从高地址位向低地
址位增长的，是一块连续的内存区域，最大容量是由系统预先定义好的，申请的栈空间超过这
个界限时会提示溢出，用户能从栈中获取的空间较小。
堆区：用于动态分配内存，位于BSS 和栈中间的地址区域。由程序员申请分配和释放。堆
是从低地址位向高地址位增长，采用链式存储结构。频繁的malloc/free 造成内存空间的不连
续，产生碎片。当申请堆空间时库函数是按照一定的算法搜索可用的足够大的空间。因此堆的效
率比栈要低的多。

### 虚拟内存和物理内存怎么对应 （牛客21题）

### Linux虚拟地址空间

为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。
虚拟内存技术使得不同进程在运行过程中，它所看到的是自己独自占有了当前系统的4G 内
存。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理
内存上。事实上，在每个进程创建加载时，内核只是为进程“创建”了虚拟内存的布局，具体
就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和
代码（比如.text .data 段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就
好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据。还有进程
运行过程中，要动态分配内存，比如malloc 时，也只是分配了虚拟内存，即为这块虚拟内存对
应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。
请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与
外存的信息置换。



虚拟内存的好处：
1.扩大地址空间；
2.内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定
的内存地址提供写保护，可以防止代码或数据被恶意篡改。
3.公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。
4.当进程通信时，可采用虚存共享的方式实现。
5.当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样
的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存
6.虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个
程序等待它的一部分读入内存时，可以把CPU 交给另一个进程使用。在内存中可以保留多个进程，
系统并发度提高



7.在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要
实际物理内存的连续空间，可以利用碎片
虚拟内存的代价：
1.虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存
2.虚拟地址到物理地址的转换，增加了指令的执行时间。
3.页面的换入换出需要磁盘I/O，这是很耗时的
4.如果一页中只有一部分数据，会浪费内存。

### 操作系统中的缺页中断 

malloc()和mmap()等内存分配函数，在分配时只是建立了进程虚拟地址空间，并没有分配
虚拟内存对应的物理内存。当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一
个缺页异常。
缺页中断：在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存
在于内存中。每当所要访问的页面不在内存是，会产生一次缺页中断，此时操作系统会根据页表
中的外存地址在外存中找到所缺的一页，将其调入内存。
缺页本身是一种中断，与一般的中断一样，需要经过4 个处理步骤：
1、保护CPU 现场
2、分析中断原因

3、转入缺页中断处理程序进行处理
4、恢复CPU 现场，继续执行
但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因
此，与一般的中断存在区别：
1、在指令执行期间产生和处理缺页中断信号
2、一条指令在执行期间，可能产生多次缺页中断
3、缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。 

### 并发(concurrency)和并行(parallelism) 的区别

并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核cpu 上的多任
务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令
之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提
高效率。
并行（parallelism）：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行
在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条
指令。这样说来并行的确提高了计算机的效率。所以现在的cpu 都是往多核方面发展。

### 操作系统中的页表寻址 （牛客书9题）

### OS**缺页置换算法** 

当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁
盘对换区，替换一个页，这种现象叫做缺页置换。当前操作系统最常采用的缺页置换算法如下：
先进先出(FIFO)算法：置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按
照进入内存的先后次序排列成队列，从队尾进入，从队首删除。
最近最少使用（LRU）算法: 置换最近一段时间以来最长时间未访问过的页面。根据程序局
部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近
不会被访问。
当前最常采用的就是LRU 算法。

### 操作系统中的结构体对齐，字节对齐 

1、原因：
1）平台原因（移植原因）：不是所有的硬件平台都能访问任意地址上的任意数据的；某些
硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。
2）性能原因：数据结构（尤其是栈）应该尽可能地在自然边界上对齐。原因在于，为了访
问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次访问。
2、规则

1）数据成员对齐规则：结构(struct)(或联合(union))的数据成员，第一个数据成员放在
offset 为0 的地方，以后每个数据成员的对齐按照#pragma pack 指定的数值和这个数据成员自
身长度中，比较小的那个进行。
2）结构(或联合)的整体对齐规则：在数据成员完成各自对齐之后，结构(或联合)本身也要
进行对齐，对齐将按照#pragma pack 指定的数值和结构(或联合)最大数据成员长度中，比较小
的那个进行。
3）结构体作为成员：如果一个结构里有某些结构体成员，则结构体成员要从其内部最大元
素大小的整数倍地址开始存储。
3、定义结构体对齐
可以通过预编译命令#pragma pack(n)，n=1,2,4,8,16 来改变这一系数，其中的n 就是指定
的“对齐系数”。

4、举例
#pragma pack(2)
struct AA {
int a; //长度4 > 2 按2 对齐；偏移量为0；存放位置区间[0,3]
char b; //长度1 < 2 按1 对齐；偏移量为4；存放位置区间[4]
short c; //长度2 = 2 按2 对齐；偏移量要提升到2 的倍数6；存放位置区间[6,7]
char d; //长度1 < 2 按1 对齐；偏移量为7；存放位置区间[8]；共九个字节
};
#pragma pack()

### 虚拟内存置换的方式（24题）

### A* **a = new A; a->i = 10;****在内核中的内存分配上发生了什么（29题）

2、A* a = new A; a->i = 10：
1）A *a：a 是一个局部变量，类型为指针，故而操作系统在程序栈区开辟4/8 字节的空间
（0x000m），分配给指针a。
2）new A：通过new 动态的在堆区申请类A 大小的空间（0x000n）。
3）a = new A：将指针a 的内存区域填入栈中类A 申请到的地址的地址。即*（0x000m）=0x000n。
4）a->i：先找到指针a 的地址0x000m，通过a 的值0x000n 和i 在类a 中偏移offset，得
到a->i 的地址0x000n + offset，进行*(0x000n + offset) = 10 的赋值操作，即内存0x000n +
offset 的值是10。

### 一个类里面有static，virtual，说说这个类的内存分布 

1、static 修饰符
1）static 修饰成员变量
对于非静态数据成员，每个类对象都有自己的拷贝。而静态数据成员被当做是类的成员，无
论这个类被定义了多少个，静态数据成员都只有一份拷贝，为该类型的所有对象所共享(包括其
派生类)。所以，静态数据成员的值对每个对象都是一样的，它的值可以更新。
因为静态数据成员在全局数据区分配内存，属于本类的所有对象共享，所以它不属于特定的
类对象，在没有产生类对象前就可以使用。
2）static 修饰成员函数
与普通的成员函数相比，静态成员函数由于不是与任何的对象相联系，因此它不具有this
指针。从这个意义上来说，它无法访问属于类对象的非静态数据成员，也无法访问非静态成员函
数，只能调用其他的静态成员函数。
Static 修饰的成员函数，在代码区分配内存。

2、C++继承和虚函数
C++多态分为静态多态和动态多态。静态多态是通过重载和模板技术实现，在编译的时候确
定。动态多态通过虚函数和继承关系来实现，执行动态绑定，在运行的时候确定。
动态多态实现有几个条件：
(1) 虚函数；
(2) 一个基类的指针或引用指向派生类的对象；
基类指针在调用成员函数(虚函数)时，就会去查找该对象的虚函数表。虚函
数表的地址在每个对象的首地址。查找该虚函数表中该函数的指针进行调用。
每个对象中保存的只是一个虚函数表的指针，C++内部为每一个类维持一个
虚函数表，该类的对象的都指向这同一个虚函数表。
虚函数表中为什么就能准确查找相应的函数指针呢？因为在类设计的时候，
虚函数表直接从基类也继承过来，如果覆盖了其中的某个虚函数，那么虚函数表的指针就会被替
换，因此可以根据指针准确找到该调用哪个函数。



3、virtual 修饰符
如果一个类是局部变量则该类数据存储在栈区，如果一个类是通过new/malloc 动态申请的，
则该类数据存储在堆区。
如果该类是virutal 继承而来的子类，则该类的虚函数表指针和该类其他成员一起存储。
虚函数表指针指向只读数据段中的类虚函数表，虚函数表中存放着一个个函数指针，函数指针指
向代码段中的具体函数。

### 软链接和硬链接区别

为了解决文件共享问题，Linux 引入了软链接和硬链接。除了为Linux 解决文件共享使用，
还带来了隐藏文件路径、增加权限安全及节省存储等好处。若1 个inode 号对应多个文件名，则
为硬链接，即硬链接就是同一个文件使用了不同的别名,使用ln 创建。若文件用户数据块中存放
的内容是另一个文件的路径名指向，则该文件是软连接。软连接是一个普通文件，有自己独立的
inode,但是其数据块内容比较特殊。 

### 什么是大端小端以及如何判断大端小端 

大端是指低字节存储在高地址；小端存储是指低字节存储在低地址。我们可以根据联合体来
判断该系统是大端还是小端。因为联合体变量总是从低地址存储。

![7](C:\Users\yuhexue\Desktop\7.png)

### 静态变量什么时候初始化 

静态变量存储在虚拟地址空间的数据段和bss 段，C 语言中其在代码执行之前初始化，属于
编译期初始化。而C++中由于引入对象，对象生成必须调用构造函数，因此C++规定全局或局部
静态对象当且仅当对象首次用到时进行构造

### 源码到可执行文件的过程

1）预编译
主要处理源代码文件中的以“#”开头的预编译指令。处理规则见下
1、删除所有的#define，展开所有的宏定义。
2、处理所有的条件预编译指令，如“#if”、“#endif”、“#ifdef”、“#elif”和“#else”。
3、处理“#include”预编译指令，将文件内容替换到它的位置，这个过程是递归进行的，文件
中包含其他文件。
4、删除所有的注释，“//”和“/**/”。
5、保留所有的#pragma 编译器指令，编译器需要用到他们，如：#pragma once 是为了防止有文
件被重复引用。
6、添加行号和文件标识，便于编译时编译器产生调试用的行号信息，和编译时产生编译错误或
警告是能够显示行号。
2）编译

把预编译之后生成的xxx.i 或xxx.ii 文件，进行一系列词法分析、语法分析、语义分析及优化
后，生成相应的汇编代码文件。
1、词法分析：利用类似于“有限状态机”的算法，将源代码程序输入到扫描机中，将其中的字
符序列分割成一系列的记号。
2、语法分析：语法分析器对由扫描器产生的记号，进行语法分析，产生语法树。由语法分析器
输出的语法树是一种以表达式为节点的树。

3、语义分析：语法分析器只是完成了对表达式语法层面的分析，语义分析器则对表达式是否有
意义进行判断，其分析的语义是静态语义——在编译期能分期的语义，相对应的动态语义是在运
行期才能确定的语义。
4、优化：源代码级别的一个优化过程。
5、目标代码生成：由代码生成器将中间代码转换成目标机器代码，生成一系列的代码序列——
汇编语言表示。
6、目标代码优化：目标代码优化器对上述的目标机器代码进行优化：寻找合适的寻址方式、使
用位移来替代乘法运算、删除多余的指令等。
3）汇编
将汇编代码转变成机器可以执行的指令(机器码文件)。汇编器的汇编过程相对于编译器来说更
简单，没有复杂的语法，也没有语义，更不需要做指令优化，只是根据汇编指令和机器指令的对
照表一一翻译过来，汇编过程有汇编器as 完成。经汇编之后，产生目标文件(与可执行文件格式
几乎一样)xxx.o(Windows 下)、xxx.obj(Linux 下)。
4）链接
将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和
动态链接：

1、静态链接：
函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，链接
器从库中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。
空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对
同一个目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本；
更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。
运行速度快：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何
东西，在执行的时候运行速度快。
2、动态链接：
动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在
一起形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文
件。
共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多
分，副本，而是这多个程序在执行时共享同一份副本；
更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下
一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。

性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有
一定损失。

### 微内核与宏内核

宏内核：除了最基本的进程、线程管理、内存管理外，将文件系统，驱动，网络协议等等
都集成在内核里面，例如linux 内核。
优点：效率高。
缺点：稳定性差，开发过程中的bug 经常会导致整个系统挂掉。
微内核：内核中只有最基本的调度、内存管理。驱动、文件系统等都是用户态的守护进程
去实现的。
优点：稳定，驱动等的错误只会导致相应进程死掉，不会导致整个系统都崩溃
缺点：效率低。典型代表QNX，QNX 的文件系统是跑在用户态的进程，称为resmgr 的东西，
是订阅发布机制，文件系统的错误只会导致这个守护进程挂掉。不过数据吞吐量就比较不乐观了。

### 实现线程池

1.设置一个生产者消费者队列，作为临界资源
2.初始化n 个线程，并让其运行起来，加锁去队列取任务运行
3.当任务队列为空的时候，所有线程阻塞
4.当生产者队列来了一个任务后，先对队列加锁，把任务挂在到队列上，然后使用条件变量去通
知阻塞中的一个线程





linux的内存管理机制，内存寻址方式，什么叫虚拟内存，内存调页算法，任务调度算法、

```
         Linux虚拟内存的实现需要6种机制的支持：地址映射机制、内存分配回收机制、缓存和刷新机制、请求页机制、交换机制和内存共享机制
 
内存管理程序通过映射机制把用户程序的逻辑地址映射到物理地址。当用户程序运行时，如果发现程序中要用的虚地址没有对应的物理内存，就发出了请求页要求。如果有空闲的内存可供分配，就请求分配内存(于是用到了内存的分配和回收)，并把正在使用的物理页记录在缓存中(使用了缓存机制)。如果没有足够的内存可供分配，那么就调用交换机制；腾出一部分内存。另外，在地址映射中要通过TLB(翻译后援存储器)来寻找物理页；交换机制中也要用到交换缓存，并且把物理页内容交换到交换文件中，也要修改页表来映射文件地址。
进程和线程、进程间及线程通信方式、共享内存的使用实现原理
```

死锁必要条件及避免算法、

```
1、资源不能共享，只能由一个进程使用。
2、请求与保持（Hold andwait）：已经得到资源的进程可以再次申请新的资源。
3、不可剥夺（Nopre-emption）：已经分配的资源不能从相应的进程中被强制地剥夺。
4、循环等待：系统中若干进程组成环路，该环路中每个进程都在等待相邻进程正占用的资源
 
处理死锁的策略：1.忽略该问题。例如鸵鸟算法，该算法可以应用在极少发生死锁的的情况下。为什么叫鸵鸟算法呢，因为传说中鸵鸟看到危险就把头埋在地底下，可能鸵鸟觉得看不到危险也就没危险了吧。跟掩耳盗铃有点像。2.检测死锁并且恢复。3.仔细地对资源进行动态分配，以避免死锁。4.通过破除死锁四个必要条件之一，来防止死锁产生。）
```

动态链接和静态链接的区别、

```
动态链接是只建立一个引用的接口，而真正的代码和数据存放在另外的可执行模块中，在运行时再装入；而静态链接是把所有的代码和数据都复制到本模块中，运行时就不再需要库了。
```

c程序辨别系统是16位or32位,大端or小端字节序、

16or32

```
法一：int k=~0;
 
if((unsigned int)k >63356) cout<<"at least 32bits"<<endl;
else cout<<"16 bits"<<endl;
 
法二：//32为系统
 
int i=65536;
cout<<i<<endl;
int j=65535;
cout<<j<<endl;
```

大or小

1) Little-Endian就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。
2) Big-Endian就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。
举一个例子，比如数字0x12 34 56 78在内存中的表示形式为：

1)大端模式：
低地址 -----------------> 高地址
0x12  |  0x34  |  0x56  |  0x78
2)小端模式：
低地址 ------------------> 高地址
0x78  |  0x56  |  0x34  |  0x12

32bit宽的数0x12345678在Little-endian模式以及Big-endian模式）CPU内存中的存放方式（假设从地址0x4000开始存放）为：
内存地址 小端模式存放内容   大端模式存放内容
0x4000  0x78     0x12
0x4001  0x56     0x34
0x4002  0x34     0x56
0x4003  0x12     0x78

4)大端小端没有谁优谁劣，各自优势便是对方劣势：
小端模式 ：强制转换数据不需要调整字节内容，1、2、4字节的存储方式一样。
大端模式 ：符号位的判定固定为第一个字节，容易判断正负。


BOOL IsBigEndian()  
{  
    int a = 0x1234;  
    char b =  *(char *)&a;  //通过将int强制类型转换成char单字节，通过判断起始存储位置。即等于 取b等于a的低地址部分  
    if( b == 0x12)  
    {  
        return TRUE;  
    }  
    return FALSE;  
}

联合体union的存放顺序是所有成员都从低地址开始存放，利用该特性可以轻松地获得了CPU对内存采用Little-endian还是Big-endian模式读写：

BOOL IsBigEndian()  
{  
    union NUM  
    {  
        int a;  
        char b;  
    }num;  
    num.a = 0x1234;  
    if( num.b == 0x12 )  
    {  
        return TRUE;  
    }  
    return FALSE;  
}

一般操作系统都是小端，而通讯协议是大端的。
常见CPU的字节序
Big Endian : PowerPC、IBM、Sun
Little Endian : x86、DEC
ARM既可以工作在大端模式，也可以工作在小端模式。



如何实现守护进程

```
守护进程最重要的特性是后台运行。              
 
1. 在后台运行。
 
为避免挂起控制终端将Daemon放入后台执行。方法是在进程中调用fork使父进程终止，让Daemon在子进程中后台执行。
 
if(pid=fork())
exit(0); //是父进程，结束父进程，子进程继续
2. 脱离控制终端，登录会话和进程组
 
有必要先介绍一下Linux中的进程与控制终端，登录会话和进程组之间的关系：进程属于一个进程组，进程组号（GID）就是进程组长的进程号（PID）。登录会话可以包含多个进程组。这些进程组共享一个控制终端。这个控制终端通常是创建进程的登录终端。控制终端，登录会话和进程组通常是从父进程继承下来的。我们的目的就是要摆脱它们，使之不受它们的影响。方法是在第1点的基础上，调用setsid()使进程成为会话组长：
 
setsid();
 
说明：当进程是会话组长时setsid()调用失败。但第一点已经保证进程不是会话组长。setsid()调用成功后，进程成为新的会话组长和新的进程组长，并与原来的登录会话和进程组脱离。由于会话过程对控制终端的独占性，进程同时与控制终端脱离。
 
3. 禁止进程重新打开控制终端
 
现在，进程已经成为无终端的会话组长。但它可以重新申请打开一个控制终端。可以通过使进程不再成为会话组长来禁止进程重新打开控制终端：
 
if(pid=fork()) exit(0); //结束第一子进程，第二子进程继续（第二子进程不再是会话组长）
 
4. 关闭打开的文件描述符
 
进程从创建它的父进程那里继承了打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误。按如下方法关闭它们：
 
for(i=0;i 关闭打开的文件描述符close(i);>
 
5. 改变当前工作目录
 
进程活动时，其工作目录所在的文件系统不能卸下。一般需要将工作目录改变到根目录。对于需要转储核心，写运行日志的进程将工作目录改变到特定目录如 /tmpchdir("/")
 
6. 重设文件创建掩模
 
进程从创建它的父进程那里继承了文件创建掩模。它可能修改守护进程所创建的文件的存取位。为防止这一点，将文件创建掩模清除：umask(0);
 
7. 处理SIGCHLD信号
 
处理SIGCHLD信号并不是必须的。但对于某些进程，特别是服务器进程往往在请求到来时生成子进程处理请求。如果父进程不等待子进程结束，子进程将成为僵尸进程（zombie）从而占用系统资源。如果父进程等待子进程结束，将增加父进程的负担，影响服务器进程的并发性能。在Linux下可以简单地将 SIGCHLD信号的操作设为SIG_IGN。
 
signal(SIGCHLD,SIG_IGN);
 
这样，内核在子进程结束时不会产生僵尸进程。这一点与BSD4不同，BSD4下必须显式等待子进程结束才能释放僵尸进程。

```





标准库函数和系统调用的区别，

```
1、系统调用
 
系统调用提供的函数如open, close, read, write, ioctl等，需包含头文件unistd.h。以write为例：其函数原型为 size_t write(int fd, const void *buf, size_t nbytes)，其操作对象为文件描述符或文件句柄fd(file descriptor)，要想写一个文件，必须先以可写权限用open系统调用打开一个文件，获得所打开文件的fd，例如fd=open(/"/dev/video/", O_RDWR)。fd是一个整型值，每新打开一个文件，所获得的fd为当前最大fd加1。Linux系统默认分配了3个文件描述符值：0－standard input，1－standard output，2－standard error。
 
系统调用通常用于底层文件访问（low-level file access），例如在驱动程序中对设备文件的直接访问。
 
系统调用是操作系统相关的，因此一般没有跨操作系统的可移植性。
 
系统调用发生在内核空间，因此如果在用户空间的一般应用程序中使用系统调用来进行文件操作，会有用户空间到内核空间切换的开销。事实上，即使在用户空间使用库函数来对文件进行操作，因为文件总是存在于存储介质上，因此不管是读写操作，都是对硬件（存储器）的操作，都必然会引起系统调用。也就是说，库函数对文件的操作实际上是通过系统调用来实现的。例如C库函数fwrite()就是通过write()系统调用来实现的。
 
这样的话，使用库函数也有系统调用的开销，为什么不直接使用系统调用呢？这是因为，读写文件通常是大量的数据（这种大量是相对于底层驱动的系统调用所实现的数据操作单位而言），这时，使用库函数就可以大大减少系统调用的次数。这一结果又缘于缓冲区技术。在用户空间和内核空间，对文件操作都使用了缓冲区，例如用fwrite写文件，都是先将内容写到用户空间缓冲区，当用户空间缓冲区满或者写操作结束时，才将用户缓冲区的内容写到内核缓冲区，同样的道理，当内核缓冲区满或写结束时才将内核缓冲区内容写到文件对应的硬件媒介。
2、库函数调用
 
标准C库函数提供的文件操作函数如fopen, fread, fwrite, fclose,fflush, fseek等，需包含头文件stdio.h。以fwrite为例，其函数原型为size_t fwrite(const void *buffer,size_t size, size_t item_num, FILE *pf)，其操作对象为文件指针FILE *pf，要想写一个文件，必须先以可写权限用fopen函数打开一个文件，获得所打开文件的FILE结构指针pf，例如pf=fopen(/"~/proj/filename/",/"w/")。实际上，由于库函数对文件的操作最终是通过系统调用实现的，因此，每打开一个文件所获得的FILE结构指针都有一个内核空间的文件描述符fd与之对应。同样有相应的预定义的FILE指针：stdin－standard input，stdout－standard output，stderr－standard error。
 
库函数调用通常用于应用程序中对一般文件的访问。
 
库函数调用是系统无关的，因此可移植性好。
 
由于库函数调用是基于C库的，因此也就不可能用于内核空间的驱动程序中对设备的操作
```





Apache 模型（Process Per Connection，简称PPC），TPC（ThreadPer Connection）模型，以及 select 模型和 poll 模型，epoll模型

```
一般来说，程序进行输入操作有两步：
1．等待有数据可以读
2．将数据从系统内核中拷贝到程序的数据区。
 
对于sock编程来说:
 
         第一步:   一般来说是等待数据从网络上传到本地。当数据包到达的时候，数据将会从网络层拷贝到内核的缓存中；
 
         第二步:   是从内核中把数据拷贝到程序的数据区中。
 
 
 
阻塞I/O模式                           //进程处于阻塞模式时，让出CPU，进入休眠状态
        阻塞 I/O 模式是最普遍使用的 I/O 模式。是Linux系统下缺省的IO模式。
 
       大部分程序使用的都是阻塞模式的 I/O 。
 
       一个套接字建立后所处于的模式就是阻塞 I/O 模式。（因为Linux系统默认的IO模式是阻塞模式）
 
 
对于一个UDP 套接字来说，数据就绪的标志比较简单：
（1）已经收到了一整个数据报
（2）没有收到。
而 TCP 这个概念就比较复杂，需要附加一些其他的变量。
 
       一个进程调用 recvfrom  ，然后系统调用并不返回知道有数据报到达本地系统，然后系统将数据拷贝到进程的缓存中。（如果系统调用收到一个中断信号，则它的调用会被中断）
 
   我们称这个进程在调用recvfrom一直到从recvfrom返回这段时间是阻塞的。当recvfrom正常返回时，我们的进程继续它的操作
 
 
非阻塞模式I/O                          //非阻塞模式的使用并不普遍，因为非阻塞模式会浪费大量的CPU资源。
       当我们将一个套接字设置为非阻塞模式，我们相当于告诉了系统内核： “当我请求的I/O 操作不能够马上完成，你想让我的进程进行休眠等待的时候，不要这么做，请马上返回一个错误给我。”
      我们开始对 recvfrom 的三次调用，因为系统还没有接收到网络数据，所以内核马上返回一个EWOULDBLOCK的错误。
 
      第四次我们调用 recvfrom 函数，一个数据报已经到达了，内核将它拷贝到我们的应用程序的缓冲区中，然后 recvfrom 正常返回，我们就可以对接收到的数据进行处理了。
      当一个应用程序使用了非阻塞模式的套接字，它需要使用一个循环来不听的测试是否一个文件描述符有数据可读(称做 polling(轮询))。应用程序不停的 polling 内核来检查是否 I/O操作已经就绪。这将是一个极浪费 CPU资源的操作。这种模式使用中不是很普遍。
 
 
 
 例如:
 
         对管道的操作，最好使用非阻塞方式！
 
 
 
I/O多路复用                            //针对批量IP操作时，使用I/O多路复用，非常有好。
 
       在使用 I/O 多路技术的时候，我们调用select()函数和 poll()函数或epoll函数(2.6内核开始支持)，在调用它们的时候阻塞，而不是我们来调用 recvfrom（或recv）的时候阻塞。
       当我们调用 select函数阻塞的时候，select 函数等待数据报套接字进入读就绪状态。当select函数返回的时候，也就是套接字可以读取数据的时候。这时候我们就可以调用 recvfrom函数来将数据拷贝到我们的程序缓冲区中。
        对于单个I/O操作，和阻塞模式相比较，select()和poll()或epoll并没有什么高级的地方。
 
       而且，在阻塞模式下只需要调用一个函数：
 
                            读取或发送函数。
 
                  在使用了多路复用技术后，我们需要调用两个函数了：
 
                             先调用 select()函数或poll()函数，然后才能进行真正的读写。
 
       多路复用的高级之处在于::
 
             它能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。
 
 
 
IO 多路技术一般在下面这些情况中被使用：
1、当一个客户端需要同时处理多个文件描述符的输入输出操作的时候（一般来说是标准的输入输出和网络套接字)，I/O 多路复用技术将会有机会得到使用。
2、当程序需要同时进行多个套接字的操作的时候。
3、如果一个 TCP 服务器程序同时处理正在侦听网络连接的套接字和已经连接好的套接字。
4、如果一个服务器程序同时使用 TCP 和 UDP 协议。
5、如果一个服务器同时使用多种服务并且每种服务可能使用不同的协议（比如 inetd就是这样的）。
 
 
异步IO模式有::
 
      1、信号驱动I/O模式
 
       2、异步I/O模式
 
信号驱动I/O模式                                                  //自己没有用过。
 
       我们可以使用信号，让内核在文件描述符就绪的时候使用 SIGIO 信号来通知我们。我们将这种模式称为信号驱动 I/O 模式。
 
为了在一个套接字上使用信号驱动 I/O 操作，下面这三步是所必须的。
（1）一个和 SIGIO信号的处理函数必须设定。
（2）套接字的拥有者必须被设定。一般来说是使用 fcntl 函数的 F_SETOWN 参数来
进行设定拥有者。
（3）套接字必须被允许使用异步 I/O。一般是通过调用 fcntl 函数的 F_SETFL 命令，O_ASYNC为参数来实现。
 
       虽然设定套接字为异步 I/O 非常简单，但是使用起来困难的部分是怎样在程序中断定产生 SIGIO信号发送给套接字属主的时候，程序处在什么状态。
 
1．UDP 套接字的 SIGIO 信号                   (比较简单)
在 UDP 协议上使用异步 I/O 非常简单．这个信号将会在这个时候产生：
 
1、套接字收到了一个数据报的数据包。
2、套接字发生了异步错误。
        当我们在使用 UDP 套接字异步 I/O 的时候，我们使用 recvfrom()函数来读取数据报数据或是异步 I/O 错误信息。
2．TCP 套接字的 SIGIO 信号                  (不会使用)
          不幸的是，异步 I/O 几乎对 TCP 套接字而言没有什么作用。因为对于一个 TCP 套接字来说，SIGIO 信号发生的几率太高了，所以 SIGIO 信号并不能告诉我们究竟发生了什么事情。
 
在 TCP 连接中， SIGIO 信号将会在这个时候产生：
l  在一个监听某个端口的套接字上成功的建立了一个新连接。
l  一个断线的请求被成功的初始化。
l  一个断线的请求成功的结束。
l  套接字的某一个通道（发送通道或是接收通道）被关闭。
l  套接字接收到新数据。
l  套接字将数据发送出去。
 
l  发生了一个异步 I/O 的错误。
 
一个对信号驱动 I/O 比较实用的方面是NTP（网络时间协议 Network TimeProtocol）服务器，它使用 UDP。这个服务器的主循环用来接收从客户端发送过来的数据报数据包，然后再发送请求。对于这个服务器来说，记录下收到每一个数据包的具体时间是很重要的。
 
因为那将是返回给客户端的值，客户端要使用这个数据来计算数据报在网络上来回所花费的时间。图 6-8 表示了怎样建立这样的一个 UDP 服务器。
 
 
 
 
 
异步I/O模式             //比如写操作，只需用写，不一定写入磁盘(这就是异步I/O)的好处。异步IO的好处效率高。
      当我们运行在异步 I/O 模式下时，我们如果想进行 I/O 操作，只需要告诉内核我们要进行 I/O 操作，然后内核会马上返回。具体的 I/O 和数据的拷贝全部由内核来完成，我们的程序可以继续向下执行。当内核完成所有的 I/O 操作和数据拷贝后，内核将通知我们的程序。
异步 I/O 和  信号驱动I/O的区别是：
        1、信号驱动 I/O 模式下，内核在操作可以被操作的时候通知给我们的应用程序发送SIGIO 消息。
 
        2、异步 I/O 模式下，内核在所有的操作都已经被内核操作结束之后才会通知我们的应用程序。
 
select，poll，epoll
 
. Epoll 是何方神圣？
 
Epoll 可是当前在 Linux 下开发大规模并发网络程序的热门人选， Epoll 在 Linux2.6 内核中正式引入，和 select 相似，其实都 I/O 多路复用技术而已，并没有什么神秘的。
 
其实在Linux 下设计并发网络程序，向来不缺少方法，比如典型的 Apache 模型（ Process Per Connection ，简称PPC ）， TPC （ ThreadPer Connection ）模型，以及 select 模型和 poll 模型，那为何还要再引入 Epoll 这个东东呢？那还是有得说说的 …
 
2. 常用模型的缺点
 
如果不摆出来其他模型的缺点，怎么能对比出 Epoll 的优点呢。
 
2.1 PPC/TPC 模型
 
这两种模型思想类似，就是让每一个到来的连接一边自己做事去，别再来烦我。只是 PPC 是为它开了一个进程，而 TPC 开了一个线程。可是别烦我是有代价的，它要时间和空间啊，连接多了之后，那么多的进程 / 线程切换，这开销就上来了；因此这类模型能接受的最大连接数都不会高，一般在几百个左右。
 
2.2 select 模型
 
1. 最大并发数限制，因为一个进程所打开的 FD （文件描述符）是有限制的，www.linuxidc.com 由FD_SETSIZE 设置，默认值是 1024/2048 ，因此 Select 模型的最大并发数就被相应限制了。自己改改这个 FD_SETSIZE ？想法虽好，可是先看看下面吧 …
 
2. 效率问题， select 每次调用都会线性扫描全部的 FD 集合，这样效率就会呈现线性下降，把 FD_SETSIZE 改大的后果就是，大家都慢慢来，什么？都超时了？？！！
 
3. 内核 / 用户空间内存拷贝问题，如何让内核把 FD 消息通知给用户空间呢？在这个问题上 select 采取了内存拷贝方法。
 
2.3 poll 模型
 
基本上效率和select 是相同的，select 缺点的 2 和 3 它都没有改掉。
 
3. Epoll 的提升
 
把其他模型逐个批判了一下，再来看看 Epoll 的改进之处吧，其实把 select 的缺点反过来那就是 Epoll 的优点了。
 
3.1. Epoll 没有最大并发连接的限制，上限是最大可以打开文件的数目，这个数字一般远大于 2048, 一般来说这个数目和系统内存关系很大，具体数目可以 cat /proc/sys/fs/file-max 察看。
 
3.2. 效率提升， Epoll 最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中， Epoll 的效率就会远远高于 select 和 poll 。
 
3.3. 内存拷贝， Epoll 在这点上使用了“共享内存 ”，这个内存拷贝也省略了。
 
 
4. Epoll 为什么高效
 
Epoll 的高效和其数据结构的设计是密不可分的，这个下面就会提到。
 
首先回忆一下select 模型，当有I/O 事件到来时，select 通知应用程序有事件到了快去处理，而应用程序必须轮询所有的 FD 集合，测试每个 FD 是否有事件发生，并处理事件；代码像下面这样：
 
int res = select(maxfd+1, &readfds,NULL, NULL, 120);
 
if (res > 0)
 
{
 
    for (int i = 0; i <MAX_CONNECTION; i++)
 
    {
 
       if (FD_ISSET(allConnection[i], &readfds))
 
       {
 
           handleEvent(allConnection[i]);
 
       }
 
    }
 
}
 
// if(res == 0) handle timeout, res < 0handle error
 
 
Epoll 不仅会告诉应用程序有I/0事件到来，还会告诉应用程序相关的信息，这些信息是应用程序填充的，因此根据这些信息应用程序就能直接定位到事件，而不必遍历整个FD 集合。
 
int res = epoll_wait(epfd, events, 20,120);
 
for (int i = 0; i < res;i++)
 
{
 
    handleEvent(events[n]);
 
}
 
5. Epoll 关键数据结构
 
前面提到Epoll 速度快和其数据结构密不可分，其关键数据结构就是：
 
struct epoll_event {
 
    __uint32_tevents;      // Epoll events
 
    epoll_data_tdata;      // User data variable
 
};
 
typedef union epoll_data {
 
    void *ptr;
 
    int fd;
 
    __uint32_t u32;
 
    __uint64_t u64;
 
} epoll_data_t;
 
可见epoll_data 是一个 union 结构体 , 借助于它应用程序可以保存很多类型的信息 :fd 、指针等等。有了它，应用程序就可以直接定位目标了。
```

socket服务端的实现，select和epoll的区别(必问)

```
select的本质是采用32个整数的32位，即32*32= 1024来标识，fd值为1-1024。当fd的值超过1024限制时，就必须修改FD_SETSIZE的大小。这个时候就可以标识32*max值范围的fd。
 
对于单进程多线程，每个线程处理多个fd的情况，select是不适合的。
 
1.所有的线程均是从1-32*max进行扫描，每个线程处理的均是一段fd值，这样做有点浪费
 
2.1024上限问题，一个处理多个用户的进程，fd值远远大于1024
 
所以这个时候应该采用poll，
 
poll传递的是数组头指针和该数组的长度，只要数组的长度不是很长，性能还是很不错的，因为poll一次在内核中申请4K（一个页的大小来存放fd），尽量控制在4K以内
 
epoll还是poll的一种优化，返回后不需要对所有的fd进行遍历，在内核中维持了fd的列表。select和poll是将这个内核列表维持在用户态，然后传递到内核中。但是只有在2.6的内核才支持。
 
epoll更适合于处理大量的fd ，且活跃fd不是很多的情况，毕竟fd较多还是一个串行的操作
 
 
 
epoll哪些触发模式，有啥区别？（必须非常详尽的解释水平触发和边缘触发的区别，以及边缘触发在编程中要做哪些更多的确认）
 
epoll可以同时支持水平触发和边缘触发（Edge Triggered，只告诉进程哪些文件描述符刚刚变为就绪状态，它只说一遍，如果我们没有采取行动，那么它将不会再次告知，这种方式称为边缘触发），理论上边缘触发的性能要更高一些，但是代码实现相当复杂。
 
epoll同样只告知那些就绪的文件描述符，而且当我们调用epoll_wait()获得就绪文件描述符时，返回的不是实际的描述符，而是一个代表就绪描述符数量的值，你只需要去epoll指定的一个数组中依次取得相应数量的文件描述符即可，这里也使用了内存映射（mmap）技术，这样便彻底省掉了这些文件描述符在系统调用时复制的开销。
 
另一个本质的改进在于epoll采用基于事件的就绪通知方式。在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。     
```

惊群现象，

```
 举一个很简单的例子，当你往一群鸽子中间扔一块食物，虽然最终只有一个鸽子抢到食物，但所有鸽子都会被惊动来争夺，没有抢到食物的鸽子只好回去继续睡觉，等待下一块食物到来。这样，每扔一块食物，都会惊动所有的鸽子，即为惊群。对于操作系统来说，多个进程/线程在等待同一资源是，也会产生类似的效果，其结果就是每当资源可用，所有的进程/线程都来竞争资源，造成的后果：
1）系统对用户进程/线程频繁的做无效的调度、上下文切换，系统系能大打折扣。
2）为了确保只有一个线程得到资源，用户必须对资源操作进行加锁保护，进一步加大了系统开销。
 
什么是惊群
    最常见的例子就是对于socket描述符的accept操作，当多个用户进程/线程监听在同一个端口上时，由于实际只可能accept一次，因此就会产生惊群现象，当然前面已经说过了，这个问题是一个古老的问题，新的操作系统内核已经解决了这一问题。
```





```
   linux内核解决惊群问题的方法
 
    对于一些已知的惊群问题，内核开发者增加了一个“互斥等待”选项。一个互斥等待的行为与睡眠基本类似，主要的不同点在于：
    1）当一个等待队列入口有 WQ_FLAG_EXCLUSEVE 标志置位, 它被添加到等待队列的尾部. 没有这个标志的入口项, 相反, 添加到开始.
    2）当 wake_up 被在一个等待队列上调用时, 它在唤醒第一个有 WQ_FLAG_EXCLUSIVE 标志的进程后停止。
    也就是说，对于互斥等待的行为，比如如对一个listen后的socket描述符，多线程阻塞accept时，系统内核只会唤醒所有正在等待此时间的队列的第一个，队列中的其他人则继续等待下一次事件的发生，这样就避免的多个线程同时监听同一个socket描述符时的惊群问题。
```





用户态和内核态的区别

```
         虽然用户态下和内核态下工作的程序有很多差别，但最重要的差别就在于特权级的不同，即权力的不同。运行在用户态下的程序不能直接访问操作系统内核数据结构和程序，
         当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态，
```

linux文件系统：inode，inode存储了哪些东西，目录名，文件名存在哪里

```
inode包含文件的元信息，具体来说有以下内容：
　　* 文件的字节数
　　* 文件拥有者的User ID
　　* 文件的Group ID
　　* 文件的读、写、执行权限
　　* 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。
　　* 链接数，即有多少文件名指向这个inode
　　* 文件数据block的位置
　　
　inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。
每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。
 
每个inode都有一个号码，操作系统用inode号码来识别不同的文件。
这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。
表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。
 
一般情况下，文件名和inode号码是"一一对应"关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。
这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为"硬链接"（hard link）。
ln命令可以创建硬链接：ln 源文件 目标文件
 
文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的"软链接"（soft link）或者"符号链接（symbolic link）。
这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错："No such file or directory"。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode"链接数"不会因此发生变化。
 
ln -s命令可以创建软链接。：ln -s 源文文件或目录 目标文件或目录
```